---
title: Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI
author: Sam Keen
date: May 20, 2024
url: https://devthink.ai/p/building-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai
scraped_at: 2025-07-29T19:24:04.920230
---

# Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI

*By Sam Keen on May 20, 2024*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

Thank you for your continued readership! This week's edition is packed with must-read content for software developers looking to leverage the latest in generative AI. Dive into tutorials on building GraphQL-powered AI apps and implementing RAG pipelines. Don't miss the insights on AI coding assistants, open-source models, and how generative AI is reshaping UI/UX design. This is a newsletter you won't want to miss.



## ðŸ“–Â **TUTORIALS & CASE STUDIES**

**Build GraphQL-powered Generative AI Applications with Amazon Bedrock and AWS AppSync**

Read Time: 11 minutes



This article demonstrates how to integrate [Amazon Bedrock]("https://medium.com/@iggyyuson09/build-graphql-powered-generative-ai-applications-with-amazon-bedrock-and-aws-appsync-a43731545eb0")['](https://medium.com/@iggyyuson09/build-graphql-powered-generative-ai-applications-with-amazon-bedrock-and-aws-appsync-a43731545eb0"https://medium.com/@iggyyuson09/build-graphql-powered-generative-ai-applications-with-amazon-bedrock-and-aws-appsync-a43731545eb0")[s generative AI capabilities with AWS AppSync](https://medium.com/@iggyyuson09/build-graphql-powered-generative-ai-applications-with-amazon-bedrock-and-aws-appsync-a43731545eb0"https://medium.com/@iggyyuson09/build-graphql-powered-generative-ai-applications-with-amazon-bedrock-and-aws-appsync-a43731545eb0"),Â a managedÂ GraphQL service,Â to build real-time,Â serverless applications.Â It covers leveraging AWS AppSync's GraphQL SubscriptionsÂ for streaming responses,Â bypassing the 30-second timeout limit,Â and integrating with Amazon Cognito for enhancedÂ security.Â The author provides a hands-on example using the Serverless Framework and a React frontend,Â showcasing theÂ power ofÂ combining AWS AppSync and Amazon Bedrock for building responsive,Â AI-driven applications.

### **GPT-4o: Implementing a Retrieval Augmented Generation Pipeline**

Read Time: 9 minutes

This article provides a [step-by-step guide]("https://dev.to/vmesel/gpt-4o-learn-how-to-implement-a-rag-on-the-new-model-step-by-step-377d") on how software developers can leverage the new GPT-4o model and implement aÂ Retrieval Augmented Generation (RAG) system using the open-source talkdai/dialog framework.Â It covers setting up an OpenAI account,Â generating an API key,Â and integrating GPT-4o with Langchain to buildÂ a conversational agent that can retrieve and incorporate custom data.Â This tutorial equips developers with the knowledgeÂ to deploy powerful generative AI models in their applications.

### **Using Llamafiles for Embeddings in Local RAG Applications**

Read Time: 8 minutes

[This article]("https://future.mozilla.org/news/llamafiles-for-embeddings-in-local-rag-applications/")Â explores howÂ software developers can leverage llamafile,Â an efficient embedding format,Â to build local Retrieval AugmentedÂ Generation (RAG) applications.Â It recommends high-performing embedding models like Salesforce/SFR-Embedding-Mistral andÂ intfloat/e5-mistral-7b-instruct,Â and explains how to use these llamafiles with popular RAG frameworks like LlamaIndexÂ and LangChain.Â The article also details the model selection process,Â prioritizing RAG-relevant tasks from the MassiveÂ Text Embedding Benchmark.

### **4 Reasons Your AI Agent Needs a Code Interpreter**

Read Time: 8 minutes



This article explains how equipping AI agents with a code interpreter can provide them with powerful new capabilities,Â such as performing data analysis,Â generating visualizations,Â and reducingÂ hallucinations.Â [The article]("https://thenewstack.io/4-reasons-your-ai-agent-needs-code-interpreter/")Â highlights how aÂ code interpreter gives agents the ability to execute complex reasoning and test their own code output,Â making them moreÂ capable and reliable than agents relying solely on language models.

### **Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI**

Read Time: 8 minutes

[This article]("https://towardsdatascience.com/building-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8")Â demonstrates how to build a semantic research paper engine using Retrieval Augmented Generation (RAG) with LangChain,Â OpenAI's language model,Â and Chroma DB's vector database.Â The author also integrates a Copilot-embeddedÂ web application using Chainlit and adds observability features from Literal AI to monitor and debug the LLM-poweredÂ application.Â This comprehensive guide covers ingesting research papers,Â building a RAG pipeline,Â developing a CopilotÂ interface,Â and leveraging Literal AI's prompt playground and observability toolsÂ -Â providing software developers aÂ powerful toolkit for creating generative AI-powered applications.

##

## ðŸ§°Â **TOOLS**

### **Open-Source Models, Temperature Scaling, Re-Ranking, and More: Don't Miss Our Recent LLM Must-Reads**

Read Time: 8 minutes

[This article]("https://towardsdatascience.com/open-source-models-temperature-scaling-re-ranking-and-more-dont-miss-our-latest-llm-must-reads-ed8e43190333")Â highlights several recent Towards Data Science articles on the latest trends and techniques in largeÂ language models (LLMs) and generative AI.Â Topics covered include the advantages of open-source LLMs,Â the importance ofÂ temperature scaling and re-ranking for retrieval-augmented generation,Â and how LLMs can be manipulated for e-commerceÂ recommendations.Â The summary also includes links to other must-read articles on subjects like statistical convergenceÂ and transitioning from physics to data science,Â all of which would be highly valuable for software developers looking toÂ leverage generative AI in their work.

### **AnythingLLM: The AI App that Supercharges Your Docs**

Read Time: 8 minutes



[AnythingLLM]("https://github.com/Mintplex-Labs/anything-llm")Â is an all-in-one desktop and Docker AI application that enables developers to turn any document,Â resource,Â or content into context that can be used by large language models (LLMs) during chatting.Â The app supports multi-user management,Â agents,Â custom embeddable chat widgets,Â and various LLM and vector database integrationsÂ -Â all while offering cost-efficient document handling.Â Developers can self-host AnythingLLM locally or in the cloud,Â leveraging this powerful tool to build private,Â intelligently conversational AI assistants.

### **Imposing Consistent Light: A Generative AI Approach to Relighting Images**

Read Time: 8 minutes

[IC-Light]("https://github.com/lllyasviel/IC-Light")Â is a generative AI tool that allows software developers to manipulateÂ the illumination of images.Â It features text-conditioned and background-conditioned models capable of consistentlyÂ relighting portraits and objects,Â even generating normal maps from the relit images.Â This novel approach to imageÂ relighting demonstrates the potential of Generative AI to enhance creative workflows for software developers workingÂ with visuals.

### **PaliGemma: Google's Open-Source Multimodal Vision-Language Model**

Read Time: 9 minutes

[PaliGemma]("https://blog.roboflow.com/paligemma-multimodal-vision/")Â is an open-source multimodal model released byÂ Google that can be fine-tuned for tasks like image captioning,Â visual question answering,Â and object detection.Â UnlikeÂ closed-source models,Â PaliGemma allows developers to create custom AI applications by fine-tuning the model on their ownÂ data.Â The article explores PaliGemma's capabilities,Â compares it to other models,Â and provides guidance on deploying andÂ evaluating the model for computer vision use cases.

### **Aider: AI Pair Programming in Your Terminal**

Read Time: 8 minutes



[Aider]("https://aider.chat/")Â is a command-line tool that lets software developers pair program with large languageÂ models (LLMs) to edit code stored in their local Git repositories.Â Aider seamlessly integrates with popular LLMs likeÂ GPT-4o and Claude 3 Opus,Â allowing developers to request code changes,Â bug fixes,Â and other enhancements directly withinÂ their development environment.Â With features like automatic Git commits,Â repo mapping,Â and voice-to-code support,Â AiderÂ empowers developers to increase their productivity and remain competitive in the evolving software market.

## ðŸ“°Â **NEWS & EDITORIALS**

### **How Generative AI Is Remaking UI/UX Design**

Read Time: 10 minutes



[This article]("https://a16z.com/how-generative-ai-is-remaking-ui-ux-design/")Â explores how advancements in generative AIÂ are transforming the design-to-code process for software developers.Â It highlights how toolsÂ like Vercel v0 and Galileo leverage language models to streamline prototyping,Â bridge the gap betweenÂ design and implementation,Â and unlock new possibilities for dynamic,Â adaptive user interfaces.Â The article outlines keyÂ trends in AI-powered interface creation,Â from ideation to code generation,Â offering a glimpse into the future ofÂ state-based and fully adaptive software interfaces.

### **Ilya Sutskever, Co-Founder and Chief Scientist, Leaves OpenAI**

Read Time: 7 minutes

[Ilya Sutskever]("https://time.com/6978195/ilya-sutskever-leaves-open-ai/"),Â the co-founder and chief scientist of OpenAI,Â is leaving the company.Â Sutskever played a pivotal role at OpenAI since its inception,Â helping guide discussions on AIÂ safety and at times differing with CEO Sam Altman on strategy.Â His departure comes after a brief ouster of Altman lastÂ year,Â which Sutskever later regretted.Â The new chief scientist,Â Jakub Pachocki,Â led the development of OpenAI's GPT-4Â model,Â showcasing the company's continued advancement in large language model technology.

### **What OpenAI's New GPT-4o Model Means for Developers**

Read Time: 8 minutes

[OpenAI's new GPT-4o model]("https://venturebeat.com/ai/what-openais-new-gpt-4o-model-means-for-developers/")Â offersÂ significant advantages for developers,Â including faster response times,Â lower costs,Â and higher rate limits compared toÂ previous versions.Â The model's native multimodal capabilities enable new audio-first applications,Â while strong dataÂ security and privacy controls make it an attractive option for enterprise use.Â Developers can now leverage GPT-4oÂ through OpenAI's API to build advanced AI-powered features and applications for their customers and teams.

### **Hugging Face Commits $10M to Democratize AI Through Shared GPUs**

Read Time: 8 minutes

[Hugging Face]("https://www.theverge.com/2024/5/16/24156755/hugging-face-celement-delangue-free-shared-gpus-ai")Â isÂ providingÂ $10 million worth of free shared GPUs to help small developers,Â academics,Â and startups compete with techÂ giants in advancing AI technologies.Â The goal is to make state-of-the-art models accessible to everyone,Â not just largeÂ corporations,Â and prevent AI from becoming too centralized in the hands of a few organizations.

### **AI Coding Tools: Interns, Not Replacements**

Read Time: 6 minutes

[This article]("https://www.infoworld.com/article/3715462/ai-coding-tools-are-your-interns-not-your-replacement.amp.html")Â explores the role of AI coding assistants like GitHub Copilot,Â arguing they are "interns,Â not replacements" for experienced developers.Â While AI models can help average coders be more productive,Â they do not consistentlyÂ generate reliable,Â usable code.Â To effectively leverage AI in software development,Â developers need sufficientÂ experience to recognize when the AI output is flawed.Â The key is treating AI-generated code like an intern's workÂ -Â useful for routine tasks,Â but requiring careful review and testing beforeÂ deployment.

**Thanks for reading and we will see you next time**

Follow me on [twitter]("https://twitter.com/samkeen"), DM me links you would like included in a future newsletters.
