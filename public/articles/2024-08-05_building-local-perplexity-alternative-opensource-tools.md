---
title: Building a Local Perplexity Alternative with Open-Source Tools
author: Sam Keen
date: August 05, 2024
url: https://devthink.ai/p/building-local-perplexity-alternative-opensource-tools
scraped_at: 2025-07-29T19:22:28.898648
---

# Building a Local Perplexity Alternative with Open-Source Tools

*By Sam Keen on August 05, 2024*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

Thank you for being a loyal subscriber to our Generative AI newsletter! This week, we have some particularly compelling content to share. Get an inside look at building a Retrieval Augmented Generation (RAG) chatbot, learn how to fine-tune language models to detect factual inconsistencies, and explore the new GitHub Models platform that empowers developers to build with cutting-edge AI. Don't miss these insightful tutorials and the latest industry news that will keep you ahead of the curve.



## ðŸ“–Â **TUTORIALS & CASE STUDIES**

**Running a RAG Chatbot with Ollama on Fly.io**

Read Time: 9 minutes

This article details the implementation of a Retrieval-Augmented Generation (RAG) chatbot that leverages Ollama,Â anÂ open-source platform for running large language models,Â and Upstash Vector,Â a serverless vector database.Â The chatbotÂ uses the Mistral 7B language model to generate responses and Nomic Embeddings to extract relevant information from aÂ knowledge base.Â [The article]("https://upstash.com/blog/ollama-rag")Â demonstrates how to deploy the chatbot and itsÂ supporting infrastructure on Fly.io,Â a platform for running web applications globally.

### **Finetune a model to detect hallucinations**

Read time: 8 minutes



This repository demonstrates howÂ toÂ [fine-tune a Mistral AI language model]("https://github.com/mistralai/cookbook/tree/main/third_party/wandb")Â to detectÂ factual inconsistencies andÂ hallucinations in text summaries.Â It includes datasets from Factual Inconsistency Benchmark (FIB) and USB,Â andÂ integrates with WeightsÂ &Â Biases for experiment tracking.Â The project shows improvements in hallucination detectionÂ after fine-tuning,Â with detailed metrics and comparisons between modelÂ versions.

### **Building Powerful Chains and Agents in LangChain**

Read time: 10 minutes

[This article]("https://dev.to/jamesbmour/part-3-building-powerful-chains-and-agents-in-langchain-5g04")Â provides aÂ comprehensive guide to constructing sophisticated AI-driven systems using LangChain's chains and agents.Â It covers theÂ fundamentals of chains,Â explains how to integrate them with prompts and large language models (LLMs),Â and introducesÂ powerful agent capabilities that can leverage external tools to solve complex problems.Â The article equips developersÂ with the knowledge to create adaptable,Â modular,Â and reusable AI applications.

### **Building a Local Perplexity Alternative with Open-Source Tools**

Read Time: 8 minutes



This articleÂ shows software developers how to buildÂ aÂ [self-hosted AI search engine]("https://jointerminus.medium.com/building-a-local-perplexity-alternative-with-perplexica-ollama-and-searxng-71602523e256")Â similar to Perplexity,Â using open-source toolsÂ like Ollama,Â SearXNG,Â and Perplexica on the Terminus platform.Â By leveraging these tools,Â developers can create aÂ powerful,Â customizable AI search engine without monthly fees or usage limits,Â providing greater control over their dataÂ and search experience.

### **A Visual Guide to Quantization**

Read time: 20 minutes



This article providesÂ aÂ [comprehensive overview of quantization]("https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization"),Â a technique to reduce the size and improve theÂ efficiency of large language models (LLMs) by representing their parameters with fewer bits.Â It explores symmetric andÂ asymmetric quantization,Â calibration methods,Â and advanced techniques like GPTQ and BitNet that enable 4-bit and evenÂ 1-bit LLMs.Â With detailed visualizations and intuitive explanations,Â this guide equips software developers with theÂ knowledge to leverage quantization in their own projects leveraging generative AI.

##

## ðŸ§°Â **TOOLS**

### **Introducing GitHub Models: A new generation of AI engineers building on GitHub**

Read time: 5 minutes



[GitHub is launching GitHub Models]("https://github.blog/news-insights/product-news/introducing-github-models/"),Â enablingÂ over 100 million developers to become "AI engineers" and build with industry-leading AI models.Â The new interactiveÂ model playground allows users to explore and experiment with popular private and open models,Â while the integration withÂ Codespaces and Azure AI provides a seamless path to develop and deploy AI applications.Â GitHub is positioning itselfÂ as "the creator network for the age of AI" by democratizing access to cutting-edge AI technologies.

### **Introducing torchchat: Accelerating Local LLM Inference on Laptop, Desktop and Mobile**

Read time: 6 minutes



[torchchat]("https://pytorch.org/blog/torchchat-local-llm-inference/")Â is a new PyTorch library that enables seamless andÂ high-performance local inference of large language models like LLaMA 3 and 3.1 on laptops,Â desktops,Â and mobile devices.Â It provides a REST API,Â desktop binaries,Â and mobile exports,Â with impressive performance benchmarks across variousÂ hardware and quantization levels.Â This tool empowers software developers to leverage advanced generative AI capabilitiesÂ on constrained devices,Â unlocking new possibilities for their applications.

### **Dioptra: Test Software for the Characterization of AI Technologies**

Read time: 7 minutes

[Dioptra]("https://pages.nist.gov/dioptra/")Â is a software test platform for assessing the trustworthy characteristics ofÂ artificial intelligence (AI),Â such as validity,Â safety,Â security,Â and fairness.Â It provides a REST API,Â web interface,Â and Python client to design,Â manage,Â execute,Â and track experiments for evaluating AI models throughout theirÂ development lifecycle.Â Dioptra supports the NIST AI Risk Management Framework by enabling the measurement and analysisÂ of AI risks,Â making it a valuable tool for software developers building applications with generative AI.

### **Odyssey: Empowering Agents with Open-World Skills**

Read Time: 8 minutes



[Odyssey]("https://github.com/zju-vipa/Odyssey")Â is a new framework that empowers Large Language Model (LLM)-based agentsÂ with open-world skills to explore the vast Minecraft world.Â It includes a skill library of 40 primitive and 183Â compositional skills,Â a fine-tuned LLaMA-3 model trained on Minecraft Wiki data,Â and a benchmark for evaluating agentÂ planning and exploration capabilities.Â The open-source project aims to advance autonomous agent solutions and inspireÂ future research in this area.

## ðŸ“°Â **NEWS & EDITORIALS**

### **The EU's AI Act is now in force**

Read time: 8 minutes

TheÂ [European Union's risk-based regulation for AI applications]("https://techcrunch.com/2024/08/01/the-eus-ai-act-is-now-in-force/")Â has come into force,Â starting a series of complianceÂ deadlines for AI developers and users.Â The law takes a tiered approach,Â banning a few AI uses,Â regulating high-riskÂ systems,Â and requiring some transparency for "limited risk" technologies like chatbots.Â Notably,Â the law also setsÂ standards for the most powerful "general purpose" AIÂ models.

### **NVIDIA Accelerates Humanoid Robotics Development**

Read time: 8 minutes

[NVIDIA is providing a suite of services, models and computing platforms]("https://nvidianews.nvidia.com/news/nvidia-accelerates-worldwide-humanoid-robotics-development"),Â to accelerate the development of humanoid robots globally.Â Key offerings include NIM microservices for simulation and generative AI,Â the OSMO orchestration service,Â and anÂ AI-enabled teleoperation workflow.Â NVIDIA also announced a Humanoid Robot Developer Program to provide early access toÂ these technologies,Â benefiting companies like Boston Dynamics that are pushing the boundaries of humanoid robotics.

### **Why Big Tech Wants to Make AI Cost Nothing**

Read time: 8 minutes

[This article]("https://dublog.net/blog/commoditize-complement")Â discusses how major tech companies like Meta,Â Google,Â andÂ Microsoft are open-sourcing powerful Large Language Models (LLMs) to commoditize the technology.Â By making LLMs readilyÂ available,Â these companies aim to increase demand for their complementary products like cloud computing and GPUÂ hardware.Â The article explores the strategic reasoning behind this approach and the potential impact on AI startupsÂ struggling to compete with the vast resources of Big Tech.

### **Announcing New Azure AI Updates: Customizable Models and Expanded Choices**

Read Time: 8 minutes

This article highlights [key updates to the Azure AI platform]("https://azure.microsoft.com/en-us/blog/announcing-phi-3-fine-tuning-new-generative-ai-models-and-other-azure-ai-updates-to-empower-organizations-to-customize-and-scale-ai-applications/"),Â including serverless fine-tuning for Phi-3 models,Â improvements to theÂ Phi-3-mini model,Â and the addition of new models from OpenAI,Â Meta,Â and Mistral.Â It also discusses enabling safe andÂ responsible AI development through Azure AI evaluations and content safety features.Â These updates provide softwareÂ developers with greater flexibility,Â performance,Â and choice when leveraging generative AI in their applications.

**Thanks for reading and we will see you next time**

Follow me on [twitter]("https://twitter.com/samkeen"), DM me links you would like included in a future newsletter.
