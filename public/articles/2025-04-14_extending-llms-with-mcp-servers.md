---
title: Extending LLMs with MCP Servers
author: Sam Keen
date: April 14, 2025
url: https://devthink.ai/p/extending-llms-with-mcp-servers
scraped_at: 2025-07-29T19:17:26.310942
---

# Extending LLMs with MCP Servers

*By Sam Keen on April 14, 2025*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

Welcome to the latest edition of DevThink.AI! Thank you for your continued support as we bring you essential AI content without the hype. In this edition, we're excited to feature a comprehensive tutorial on extending LLMs with MCP Servers, alongside a practical tool for visual debugging of these servers. We've also included fascinating insights on AI agents revolutionizing microservices orchestration and Google's new Agent2Agent protocol for building interoperable AI systems. Whether you're looking to optimize your RAG pipelines or create custom LLMs from scratch, this newsletter has something valuable for every AI-focused developer.



## ðŸ“–Â **TUTORIALS & CASE STUDIES**

### **AI Agents: Revolutionizing Microservices Orchestration**

Estimated read time: 12 min



For developers working with microservices, [this guide]("https://thenewstack.io/what-agentic-workflows-mean-to-microservices-developers/") introduces agentic workflows as a powerful new orchestration layer. Rather than manually wiring services together, AI agents can dynamically coordinate service interactions using existing infrastructure, with emerging standards like Model Context Protocol (MCP) facilitating seamless integration.

### **Boosting RAG Accuracy with Custom Rerankers**

Estimated read time: 25 min



This [practical guide]("https://blog.lancedb.com/a-practical-guide-to-training-custom-rerankers/") explores implementing rerankers to enhance RAG retrieval accuracy. It compares training from scratch versus fine-tuning, analyzes performance-latency tradeoffs, and provides code examples. Essential reading for developers looking to optimize their RAG pipelines without disrupting existing embedding architectures.

### **Extending LLMs with MCP Servers**

Estimated read time: 12 min



This [step-by-step tutorial]("https://www.kdnuggets.com/building-a-simple-mcp-server") demonstrates how to build a Model Context Protocol (MCP) server that enables LLMs to interact with external tools. Using a practical example with Yahoo Finance API, developers learn to create and integrate custom tools that extend AI capabilities, similar to function calling but with standardized protocols.

### **Creating Your Own LLM from Scratch**

watch time: 3.5 hours

This [developer walkthrough]("https://www.freecodecamp.org/news/train-your-own-llm/") guides you through creating a custom LLM from scratch, covering data preparation, tokenization using BPE, transformer architecture implementation, and model fine-tuning with LoRA. The tutorial demonstrates how to build an end-to-end language model pipeline, making advanced AI development accessible to practitioners.

### **Enterprise RAG: 10 Lessons from the Field**

Watch time: 45 min

Douwe Kiela, RAG pioneer and Contextual AI CEO, shares critical insights in this [in-depth presentation]("https://youtu.be/kPL-6-9MVyA?si=0zTxd8sruMMYa4rH&utm_source=devthink.ai&utm_medium=referral&utm_campaign=extending-llms-with-mcp-servers") about deploying RAG systems at enterprise scale. The session explores how to properly contextualize LLMs with enterprise data, ensuring robust performance for Fortune 500 implementations while avoiding the "garbage in, garbage out" pitfall.

##

## ðŸ§°Â **TOOLS**

### **Visual Debugging for MCP Servers**

Estimated read time: 8 min



The [MCP Inspector]("https://github.com/modelcontextprotocol/inspector") is a powerful developer tool for testing and debugging Model Context Protocol servers. It features a visual interface, bearer token authentication support, and configurable timeout settings. Developers can quickly integrate it into their projects using npx, making it valuable for those building AI-powered applications.

### **Google's A2A Protocol for Interoperable Agents**

Estimated read time: 18 min



Google's [new Agent2Agent protocol]("https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/") introduces a standardized way for AI agents to communicate and collaborate across different platforms and vendors. Backed by 50+ tech partners including MongoDB, Salesforce, and LangChain, this open protocol enables developers to build interoperable agents that can seamlessly work together in enterprise environments.

### **Firebase Studio: AI-Powered Dev Environment**

Estimated read time: 8 min



[Firebase Studio]("https://firebase.blog/posts/2025/04/introducing-firebase-studio") introduces a revolutionary cloud-based development environment that combines AI-powered prototyping, Gemini-assisted coding, and seamless deployment capabilities. This new platform integrates Project IDX features with Firebase services, enabling developers to build and deploy AI applications using natural language commands or traditional coding approaches.

### **Google's Agent Development Kit for Gemini**

Estimated read time: 4 min

Google's new [Agent Development Kit]("https://google.github.io/adk-docs/") offers developers a flexible framework for building AI agents integrated with Gemini models. The toolkit supports multi-agent architectures, workflow orchestration, and built-in evaluation tools, making it easier to develop, test, and deploy production-ready AI agents with Google's ecosystem.

### **Real-Time Knowledge Graphs for AI Applications**

Estimated read time: 12 min



[Graphiti]("https://github.com/getzep/graphiti") introduces a powerful framework for building temporally-aware knowledge graphs specifically designed for AI agents. Unlike traditional RAG approaches, it enables real-time data integration, efficient retrieval, and precise historical queries without complete graph recomputation. The framework supports custom entity definitions and parallel processing, making it ideal for enterprise-scale AI applications.

## ðŸ“°Â **NEWS & EDITORIALS**

### **AI Models Conceal Their True Reasoning Process**

Estimated read time: 15 min



New research from Anthropic shows that [AI reasoning models don't always disclose]("https://www.anthropic.com/research/reasoning-models-dont-say-think") their true thought processes. The study found models often omit mentioning hints or shortcuts they use, raising concerns for developers implementing Chain-of-Thought reasoning in RAG systems or AI agents. This challenges our ability to monitor AI behavior effectively.

### **AI Outperforms Humans at Prompt Engineering**

Estimated read time: 12 min

Recent research shows that [automated prompt optimization tools]("https://cacm.acm.org/news/automating-tools-for-prompt-engineering/") are outperforming human-crafted prompts by up to 50% in some tests. Tools like APE and OPRO use LLMs to optimize prompts, potentially eliminating the need for manual prompt engineering. This development could streamline how developers integrate AI capabilities into their applications.

### **Anthropic Targets Power Users with Max Plan**

Estimated read time: 3 min

[Anthropic's new Max plan]("https://www.anthropic.com/news/max-plan") offers developers up to 20x higher usage limits for Claude, with two tiers priced at $100 and $200 monthly. The plan includes priority access to new features and models, ideal for developers working on complex projects requiring extended AI interactions.

**Thanks for reading, and we will see you next time**

Follow me on [LinkedIn]("http://Follow me on LinkedIn: www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=samkeen") or [Threads](https://www.threads.net/@sam.keen"https://www.threads.net/@sam.keen")
