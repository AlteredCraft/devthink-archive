---
title: üõ†Ô∏è Building a Slack Bot with Replit and Google LLMs
author: Unknown
date: October 12, 2023
url: https://devthink.ai/p/building-a-slack-bot-with-replit-and-google-llms
scraped_at: 2025-07-29T19:28:07.243871
---

# üõ†Ô∏è Building a Slack Bot with Replit and Google LLMs

*By Unknown on October 12, 2023*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

As always, thank you for subscribing. Feel free to contact [me]("https://twitter.com/devthinkai") with suggestions.  
If you had this forwarded, you can sign up for this weekly news letter [here]("https://devthinkai.beehiiv.com/").

In this edition:

- üìñ TUTORIALS & CASE STUDIES
- üß∞ TOOLS
- üì∞ NEWS AND EDITORIALS

## üìñ¬†**TUTORIALS & CASE STUDIES**

**Building a Slack Bot with Replit and Google LLMs**  
read time: 10 minutes



A Replit user shares their experience of [building a Slack bot]("https://blog.replit.com/building-my-first-slack-bot") using Google's Large Language Models (LLMs) and Replit's AI capabilities. The bot provides daily channel summaries, demonstrating the power and accessibility of AI tools for developers of all skill levels.

**Integrating Foundation Models into Your Code with Amazon Bedrock**  
watch time: 12 minutes  
In this [video]("https://www.youtube.com/watch?v=ab1mbj0acDo&utm_source=devthink.ai&utm_medium=referral&utm_campaign=building-a-slack-bot-with-replit-and-google-llms"), Mike Chambers of AWS showcases integrating foundation models using Amazon Bedrock. Easily import using Boto3 in Python, fetch API parameters from the Bedrock console, and even stream model outputs for real-time interactions.

**Efficient Fine-Tuning with Hugging Face‚Äôs PEFT Library**  
read time: 15 minutes  
This [article]("https://pub.towardsai.net/fine-tuning-models-using-prompt-tuning-with-hugging-faces-peft-library-998ae361ee27") explores the use of Hugging Face's PEFT library for efficient fine-tuning of large language models using Prompt Tuning. The technique allows for memory savings by enabling multiple models with different purposes to reside in memory while loading only one pretrained model.

**Mastering Customer Segmentation with LLM**  
read time: 8 minutes  
Learn advanced customer segmentation techniques using LLMs and improve clustering models with advanced techniques. This article explores three methods for customer segmentation: Kmeans, K-Prototype, and LLM + Kmeans. It also covers dimensionality reduction techniques such as PCA, t-SNE, and MCA. The article provides code examples and visualizations to help understand the concepts. Read more [here]("https://towardsdatascience.com/mastering-customer-segmentation-with-llm-3d9008235f41").

##

## üß∞¬†**TOOLS**

**OpenLLMetry: Open-source Observability for LLM Applications**  
read time: 10 minutes



OpenLLMetry, an open-source extension built on OpenTelemetry, provides complete observability for your LLM application. It's compatible with existing observability solutions like Datadog and Honeycomb. Developed by Traceloop, it includes standard OpenTelemetry instrumentations for LLM providers and Vector DBs. Check out the [OpenLLMetry GitHub repo]("https://github.com/traceloop/openllmetry") for more details.

**LLaVa: A New Approach to Visual Instruction Tuning**  
read time: 8 minutes  
Researchers have developed a new method for instruction tuning large language models (LLMs) in the multimodal field, called [LLaVa]("https://llava-vl.github.io/"). Using the COCO dataset, they collected 158K unique language-image instruction-following samples and connected pre-trained CLIP ViT-L/14 visual encoder and large language model Vicuna. The evaluation showed LLaVa achieving 85.1% relative score compared with GPT-4, indicating the effectiveness of the proposed self-instruct method in multimodal settings.

**Introducing ctoc: A Tool for Token Analysis in Large Language Models**  
read time: 8 minutes  
ctoc is a new, lightweight tool for analyzing codebases at the token level, crucial for Large Language Model's (LLM) memory and conversation history. Built on gocloc, it's extremely fast and provides insights into tokenization, vocabulary size, and tokenization cost. Check out [ctoc on GitHub]("https://github.com/yaohui-wyh/ctoc") for more details.

**Introducing MiniGPT-5: A Leap in Vision-and-Language Generation**  
read time: 10 minutes  
Researchers have introduced [MiniGPT-5]("https://github.com/eric-ai-lab/MiniGPT-5"), a model that leverages 'generative vokens' for interleaved vision-and-language generation. The model, which requires no comprehensive image descriptions for training, has shown significant improvement over the baseline Divter model on the MMDialog dataset and performed well on the VIST dataset.

**TurboPuffer: The New Serverless Vector Database**  
read time: 10 minutes  
TurboPuffer, a new serverless vector database, offers cost-effective and reasonably fast services. It's 10-70x cheaper than other vector databases, with a latency of ~100ms on 1m vectors. Although official API clients are yet to be released, the API is simple to use. Check out the [official website]("https://turbopuffer.com/") for more details.

## üì∞¬†**NEWS & EDITORIAL**

**A Developer's Guide to Open Source LLMs and Generative AI**  
read time: 10 minutes  
This [article]("https://github.blog/2023-10-05-a-developers-guide-to-open-source-llms-and-generative-ai/") provides insights into the benefits and challenges of open source Large Language Models (LLMs), how to fine-tune them, and the future of open source LLMs. It also introduces several open source LLMs available today, including OpenLLaMA, Falcon-Series, MPT-Series, and FastChat-T5.

**The AI Pause Debate: A Comprehensive Overview**  
read time: 30 minutes  
This [article]("https://www.astralcodexten.com/p/pause-for-thought-the-ai-pause-debate") provides an in-depth analysis of the ongoing debate about pausing AI development. It explores various perspectives, including those advocating for a simple pause, a surgical pause, a regulatory pause, a total stop, or no pause at all. The discussion also touches on the potential risks and benefits of each approach, as well as the practicality and implications of implementing them.

**The AI Revolution: A New Era in Technology**  
read time: 20 minutes  
This [article]("https://www.digitalnative.tech/p/the-mobile-revolution-vs-the-ai-revolution") explores the AI revolution, comparing it to past technological revolutions like the mobile and internet revolutions. It argues that AI represents a more fundamental shift in technology, marking the transition from the 'Information Age' to a new era where computers mimic the human brain. The piece also discusses the potential opportunities this shift presents for startups and the tech industry at large.

**Is AI the Next Platform Shift in Software Development?**  
read time: 8 minutes  
This [article]("https://matt-rickard.com/is-ai-a-platform-shift") explores whether AI represents a platform shift in software development, similar to previous shifts like personal computers, the internet, mobile, and cloud. It discusses how AI could change distribution, business models, and what's possible in software development, concluding that AI is likely to be a significant platform shift.

**The Complexities of Evaluating AI Systems: Insights from Anthropic**  
read time: 20 minutes  
Anthropic shares their experiences and challenges in [evaluating AI systems]("https://www.anthropic.com/index/evaluating-ai-systems"), discussing multiple choice evaluations, third-party frameworks, human evaluations, and model-generated evaluations. They highlight the difficulty in developing robust evaluations and the importance of effective AI governance. The post concludes with policy recommendations to advance the science and engineering of evaluations.

**Replit AI opens up access to tools**  
read time: 5 minutes  
Replit has made its AI features available to all developers, enhancing code completion and assistance. The new [replit-code-v1.5-3b]("https://blog.replit.com/ai4all"), a state-of-the-art 3B LLM, will further boost code completion capabilities. The company's future roadmap emphasizes AI's role in redefining every Replit feature.

**Thanks for reading and we will see you next time**

Follow me on [twitter]("https://twitter.com/devthinkai"), DM me links you would like included in a future newsletters.
