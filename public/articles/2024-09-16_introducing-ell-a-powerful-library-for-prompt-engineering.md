---
title: A Simple Framework for RAG Enhanced Visual Question Answering
author: Sam Keen
date: September 16, 2024
url: https://devthink.ai/p/introducing-ell-a-powerful-library-for-prompt-engineering
scraped_at: 2025-07-29T19:21:37.938742
---

# A Simple Framework for RAG Enhanced Visual Question Answering

*By Sam Keen on September 16, 2024*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

Thanks for being a loyal subscriber to our newsletter! This week, we've curated some truly engaging content that I think you'll find immensely valuable. From a deep dive into Retrieval Augmented Generation pipelines to an introduction to OpenAI's new Structured Outputs feature, there's a wealth of practical knowledge to help you leverage the latest advancements in generative AI. We've also highlighted some intriguing tools like ell and Reader-LM that can streamline your prompt engineering and content conversion workflows. Dive in and discover how these insights can elevate your

AI-powered applications.



## ðŸ“–Â **TUTORIALS & CASE STUDIES**

### **Building a RAG Batch Inference Pipeline with Anyscale and Union**

Read time: 15 minutes



This article demonstrates how to build aÂ [RAG batch inference pipeline using Anyscale and Union]("https://www.anyscale.com/blog/anyscale-union-batch-inference-pipeline").Â It showcases embedding generation andÂ LLM batch inference with Ray,Â Flyte's pipeline orchestrator,Â andÂ Anyscale's model serving platform.Â The pipeline retrieves relevant context from a vector database to enhance LLMÂ responses,Â making it ideal for applications like a GitHub issue-answeringÂ chatbot.

### **Getting Started With OpenAI Structured Outputs**

Read Time: 9 minutes

[This article]("https://www.datacamp.com/tutorial/open-ai-structured-outputs")Â introduces OpenAI's new Structured OutputsÂ feature,Â which allows developers to enforce a specific output format for their LLM-powered applications.Â By definingÂ Pydantic models,Â developers can ensure responses conform to a rigid schema,Â simplifying integration with downstreamÂ systems.Â The article covers practical examples,Â best practices,Â and the benefits of using Structured Outputs,Â particularly when leveraging OpenAI's function calling capabilities.

### **AWS AI Stack: A Serverless Framework for Building AI Applications on AWS**

Read Time: 15 minutes



[AWS AI Stack]("https://github.com/serverless/aws-ai-stack")Â is a full-stack boilerplate project for building serverlessÂ AI applications on AWS.Â It provides a ready-to-use architecture featuring a React frontend,Â API Gateway,Â Lambda,Â DynamoDB,Â and AWS Bedrock for integrating large language models (LLMs) while keeping data private.Â The projectÂ demonstrates best practices for serverless development,Â including custom domains,Â CI/CD,Â authentication,Â and aÂ domain-oriented design.Â This framework enables software developers to quickly leverage the power of AI in theirÂ applications.

### **A Simple Framework for RAG Enhanced Visual Question Answering**

Read Time: 9 minutes



This article introduces a framework for enhancing Visual Question Answering using Retrieval Augmented Generation (RAG),Â whichÂ allowsÂ [the Phi-3.5-vision model]("https://towardsdatascience.com/a-simple-framework-for-rag-enhanced-visual-question-answering-06768094762e")Â to leverage Wikipedia knowledge.Â The framework generates a query tailored to the image and question,Â then retrievesÂ relevant passages to improve the accuracy and reliability of the model's answers.Â The author provides a practicalÂ implementation and discusses the benefits and limitations of this RAG-powered approach for multimodal AI assistants.

### **Python QuickStart for People Learning AI**

Read time: 10 minutes

This beginner-friendly guide introduces Python fundamentals like data types,Â variables,Â loops,Â and functionsÂ -Â essentialÂ tools for software developers building AI-powered applications.Â It then walks through an example of using Python andÂ OpenAI's API to create a research paper summarizer and keyword extractor,Â demonstrating how toÂ leverageÂ [Towards Data Science's Python QuickStart]("https://towardsdatascience.com/python-quickstart-for-people-learning-ai-58a1b76df0f4")Â for your own AI projects.

##

## ðŸ§°Â **TOOLS**

### **Introducing ell: A Powerful Library for Prompt Engineering**

Read time: 8 minutes

[ell]("https://docs.ell.so/")Â is a prompt engineering library that treats prompts as functions,Â not just strings.Â ThisÂ allows software developers to leverage powerful tools for monitoring,Â versioning,Â and visualizing their promptÂ engineering efforts.Â ell supports multimodal inputs and outputs,Â making it easier to work with language models thatÂ generate text,Â images,Â audio,Â and more.Â By focusing on simplicity and non-interference with existing workflows,Â ellÂ helps developers seamlessly integrate advanced prompt engineering techniques into their applications.

### **Reader-LM: Small Language Models for Cleaning and Converting HTML to Markdown**

Read time: 9 minutes



[Reader-LM]("https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/")Â is aÂ novel small language model (SLM) developed by Jina AI to convert raw,Â noisy HTML into clean Markdown.Â Unlike largerÂ LLMs,Â Reader-LM is designed to be cost-effective and practical,Â with models ranging from 0.5B to 1.5B parameters.Â TheÂ article details the challenges faced in training these SLMs for long-context, "selective-copy" tasks,Â and how Jina AIÂ overcame them to create a state-of-the-art solution for software developers needing to leverage generative AI tools.

### **Mistral Releases Pixtral 12B, Its First Multimodal Model**

Read Time: 7 minutes



[Mistral, a French AI startup, has released Pixtral 12B, its first multimodal model that can process both images and text]("https://techcrunch.com/2024/09/11/mistral-releases-pixtral-its-first-multimodal-model/").Â Built on Mistral's existing text model,Â Pixtral 12B can perform tasks like image captioning and object counting.Â TheÂ model is being made available on open-source platforms,Â aligning with Mistral's strategy of releasing free "open" modelsÂ and providing managed versions and consulting services to corporate customers.

### **Optimizing Inference Proxy for Large Language Models**

Read Time: 9 minutes

[The optillm project]("https://github.com/codelion/optillm")Â is an OpenAI API-compatible proxy that implementsÂ state-of-the-art techniques to improve the accuracy and performance of LLMs.Â It includes approaches like Monte CarloÂ Tree Search,Â Mixture of Agents,Â and Round Trip Optimization that can beat the frontier models on a variety of coding,Â logical,Â and mathematical tasks.Â The proxy allows software developers to leverage these advanced inference optimizationÂ techniques in their applications.

### **Composio: Equipping AI Agents with Integrated Tools**

Read time: 7 minutes



[Composio]("https://github.com/ComposioHQ/composio")Â is a production-ready toolset that equips AI agents and LLMs withÂ over 100 high-quality integrations,Â including tools for software development,Â search,Â and retrieval-augmentedÂ generation.Â It provides a single line of code to access pre-configured tools,Â manage authentication,Â and improve agenticÂ accuracy up to 40%.Â Composio is designed to be easily extended and embedded in applications,Â making it a valuableÂ resource for software developers building AI-powered solutions.

### **Replit Agent: An AI-Powered Tool to Streamline Software Development**

Read time: 7 minutes

[Replit Agent]("https://docs.replit.com/replitai/agent")Â is an experimental AI-powered tool that helps software developersÂ build applications more efficiently.Â It can understand natural language prompts and assist in creating web-basedÂ applications from scratch,Â making development more accessible.Â Replit Core and Teams subscribers can explore the agent'sÂ capabilities,Â which include prototyping,Â progress tracking,Â and deployment support,Â within a limited early accessÂ program.

## ðŸ“°Â **NEWS & EDITORIALS**

### **Introducing OpenAI o1: A New Series of Powerful Reasoning Models**

Read time: 8 minutes



[OpenAI has released a new series of AI models called o1]("https://openai.com/index/introducing-openai-o1-preview/")Â thatÂ can reason through complex tasks in science,Â coding,Â and math,Â outperforming previous models.Â These models,Â includingÂ o1-preview and the more efficient o1-mini,Â are available in ChatGPT and the OpenAI API,Â offering software developersÂ powerful tools to enhance their applications with advanced reasoning capabilities.

### **Why Cursor is Ahead of the Curve**

Read time: 7 minutes

[Cursor]("https://analyticsindiamag.com/ai-insights-analysis/why-cursor-is-ahead-of-the-curve/"),Â a code editor backed byÂ Andreessen Horowitz,Â is gaining popularity among software developers due to its advanced features and AI-poweredÂ capabilities that outshine GitHub Copilot.Â Cursor's deeper IDE integration,Â personalized suggestions,Â and flexibleÂ pricing options make it a more compelling option for developers seeking an efficient coding assistant that can boostÂ their productivity.

### **Why Open Source AI Has No Meaning**

Read Time: 9 minutes

The open source community struggles to define "open source AI" as major tech companies like Meta exploit the term forÂ their own purposes.Â The article explores the lack of stewardship over the language of open source,Â the tension betweenÂ pragmatic and aspirational approaches,Â and the complexity of issues like training data transparency.Â The authorÂ concludes that open source AI has become diminished in meaning,Â undermining the principles that have made open sourceÂ software so successful.Â Read moreÂ at: [Why Open Source AI Has No Meaning]("https://thenewstack.io/why-open-source-ai-has-no-meaning/")

### **In Defense of the Small Language Model**

Read Time: 5 minutes



[This article]("https://octo.ai/blog/in-defense-of-the-small-language-model/")Â argues that smaller,Â more efficient languageÂ models can be just as capable as larger models for many applications.Â It emphasizes the importance of model sizeÂ optimization,Â citing examples of how smaller models can achieve comparable performance to their larger counterparts.Â TheÂ article suggests that software developers should consider leveraging smaller,Â more efficient models in their RetrievalÂ Augmented Generation or Agent-based systems to reduce computational costs and carbon footprint without sacrificing modelÂ capabilities.

**Thanks for reading, and we will see you next time**

Follow me on [LinkedIn]("http://Follow me on LinkedIn: www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=samkeen") or [Threads](https://www.threads.net/@sam.keen"https://www.threads.net/@sam.keen")
