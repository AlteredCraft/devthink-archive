---
title: Smaug-72B: The New King of Open-Source AI
author: Sam Keen
date: February 11, 2024
url: https://devthink.ai/p/smaug-72b-the-new-king-of-open-source-ai
scraped_at: 2025-07-29T19:26:10.247115
---

# Smaug-72B: The New King of Open-Source AI

*By Sam Keen on February 11, 2024*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

Had a great time gathering stories for this week. Pretty active week, full of amazing tools and great strides made by open source models üê≤ .



## üìñ¬†**TUTORIALS & CASE STUDIES**

### Decoding the Transformer: A Deep Dive Beyond Attention



read time: 20 minutes  
Following an intensive 6-month investigation into the workings of a small transformer model, this [deep dive]("https://shyam.blog/posts/beyond-self-attention/") explores what happens after the multi-head self-attention process in transformers. The study reveals a new theory on how transformers generate predictions, suggesting that each transformer block learns to associate prompts with classes of strings from the training data, leading to diverse token distribution predictions.

### Setting Up a Local LLM with Chat UI in 15 Minutes

read time: 15 minutes  
This [tutorial]("https://towardsdatascience.com/set-up-a-local-llm-on-cpu-with-chat-ui-in-15-minutes-4cdc741408df") provides a step-by-step guide on how to set up a local Large Language Model (LLM) with a ChatGPT-like UI. It covers model selection, quantization, wrapping the model in an Ollama image, and setting up a chat UI using Docker and React.

### Understanding the Building Blocks of LLMs: Vectors, Tokens, and Embeddings

read time: 10 minutes  
This [tutorial]("https://thenewstack.io/the-building-blocks-of-llms-vectors-tokens-and-embeddings/") provides a comprehensive understanding of vectors, tokens, and embeddings, the fundamental components of Large Language Models (LLMs). It explains how these elements enable LLMs to process language and perform tasks with human-like versatility and accuracy.

### Enhancing Retrieval Augmented Generation with LangGraph



read time: 15 minutes  
The blog post discusses the use of LangGraph to implement self-reflective Retrieval Augmented Generation (RAG) workflows, enhancing the quality of retrieval and generation. It explores two recent self-reflective RAG papers, CRAG and Self-RAG, and demonstrates how their ideas can be implemented using LangGraph. Read more about it [here]("https://blog.langchain.dev/agentic-rag-with-langgraph/").

### Unlocking Insights from Chat Data with Streamlit

read time: 15 minutes  
This [article]("https://pub.towardsai.net/chat-analyzer-from-raw-chats-to-data-insights-d6dcbb2db1fa") showcases the development of a Streamlit data app, Chat Analyzer, designed to delve into chat data from platforms like WhatsApp and Telegram. Highlighting the journey from concept to creation, it emphasizes the app's ability to normalize disparate chat formats into a unified schema, enabling detailed analyses through various widgets.

##

## üß∞¬†**TOOLS**

### Introducing localllm: Develop AI Apps Locally Without GPUs

read time: 10 minutes  
Google Cloud introduces [localllm]("https://cloud.google.com/blog/products/application-development/new-localllm-lets-you-develop-gen-ai-apps-locally-without-gpus"), a tool that allows developers to run Large Language Models (LLMs) locally on CPUs, eliminating the need for GPUs. This tool, combined with quantized models and Cloud Workstations, enhances productivity, reduces costs, and improves data security. It integrates seamlessly with Google Cloud services, offering a comprehensive framework for AI-driven application development.

### Phidata: Building AI Assistants with Function Calling



read time: 15 minutes  
Phidata is a toolkit for building AI Assistants using function calling. It allows developers to create AI applications that can perform tasks by calling functions and choosing the next step based on the response. The toolkit provides pre-built templates for AI Apps that can be run locally or deployed to AWS with one command. Check out the full details on [Github]("https://github.com/phidatahq/phidata").

### Fabric: An Open-Source Framework for AI Augmentation

read time: 2 minutes  
Fabric is an [open-source framework]("https://github.com/danielmiessler/fabric") designed to augment human capabilities using AI. This tool could be a valuable asset for developers looking to leverage AI in their applications.

### Natural-SQL: Top Performing Text to SQL Large Language Models



read time: 2 minutes  
Explore [Natural-SQL]("https://github.com/cfahlgren1/natural-sql"), a series of top-performing Text to SQL Large Language Models (LLMs). This tool can be a game-changer for developers looking to leverage AI in their SQL database interactions, potentially simplifying and automating complex queries.

## üì∞¬†**NEWS & EDITORIALS**

### Bard Evolves into Gemini: Introducing Ultra 1.0 and a New Mobile App

read time: 8 minutes  
Google's AI model Bard has been rebranded as [Gemini]("https://blog.google/products/gemini/bard-gemini-advanced-app/"), introducing two new experiences: Gemini Advanced and a mobile app. Gemini Advanced, powered by Ultra 1.0, is a highly capable AI model excelling in complex tasks like coding and logical reasoning. It's available as part of Google One AI Premium Plan. The new mobile app allows easy access to Gemini on Android and iOS.

### Smaug-72B: The New King of Open-Source AI



read time: 10 minutes  
Abacus AI has released an open-source language model, [Smaug-72B]("https://venturebeat.com/ai/meet-smaug-72b-the-new-king-of-open-source-ai/"), which outperforms GPT-3.5 and Mistral Medium. It's the first open-source model to score over 80 across all major LLM evaluations, signaling a potential shift in AI capabilities from Big Tech to open-source.

### The Techno-Industrial Revolution: A New Era for Tech Companies

read time: 30 minutes  
The [Techno-Industrial Revolution]("https://www.notboring.co/p/the-techno-industrial-revolution") is upon us, with tech companies leveraging technology to build atom-based products with superior unit economics. Companies like Anduril, Solugen, and Monumental Labs are leading the way, using technology to deliver products more cheaply and efficiently than existing companies, capturing large markets at high margins in the process.

### OpenAI CEO Seeks Trillions for AI Chip Manufacturing

read time: 8 minutes  
OpenAI CEO Sam Altman is reportedly in talks to raise $5-7 trillion for AI chip manufacturing, addressing the scarcity of GPUs crucial for running large language models. The funding aims to significantly expand global semiconductor manufacturing capacity. Read more about this ambitious plan in [this article]("https://arstechnica.com/information-technology/2024/02/report-sam-altman-seeking-trillions-for-ai-chip-fabrication-from-uae-others/").

**Thanks for reading and we will see you next time**

Follow me on [twitter]("https://twitter.com/devthinkai"), DM me links you would like included in a future newsletters.
