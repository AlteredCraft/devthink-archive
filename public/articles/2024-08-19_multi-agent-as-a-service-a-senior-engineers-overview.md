---
title: Multi-Agent-as-a-Service â€” A Senior Engineer's Overview
author: Sam Keen
date: August 19, 2024
url: https://devthink.ai/p/multi-agent-as-a-service-a-senior-engineers-overview
scraped_at: 2025-07-29T19:22:12.068825
---

# Multi-Agent-as-a-Service â€” A Senior Engineer's Overview

*By Sam Keen on August 19, 2024*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

Thank you for being a loyal subscriber to our newsletter! This week, we have an engaging lineup of content that I'm confident you'll find valuable. Discover how large language models can enhance Optical Character Recognition, explore a powerful framework for Retrieval Augmented Generation, and learn about the latest innovations in AI-powered database development. Don't miss our deep dive into the Hacker News sentiment analysis and the latest advancements in LLM-based anomaly detection. Let's dive in!



## ðŸ“–Â **TUTORIALS & CASE STUDIES**

**Introducing workflows beta: a new way to create complex AI applications with LlamaIndex**

Read time: 11 minutes



LlamaIndex introduces a new "workflows" feature,Â an event-driven architecture that allows software developers to moreÂ easily orchestrate AI components like LLMs,Â data loaders,Â and rerankers to build complex,Â agentic AI applications.Â Workflows provide better debugging,Â observability,Â and customization compared to previous pipeline-based approaches,Â helping developers stay on the cutting edge of Generative AIÂ tooling.Â [Read more on the LlamaIndex website.]("https://www.llamaindex.ai/blog/introducing-workflows-beta-a-new-way-to-create-complex-ai-applications-with-llamaindex")

### **Exploring Generative AI: Understanding Coding Assistance Tools**

Read Time: 12 minutes

[This article]("https://martinfowler.com/articles/exploring-gen-ai.html")Â provides an in-depth exploration of GenerativeÂ AI tools and their impact on software development.Â It examines the capabilities,Â interaction modes,Â and underlyingÂ models of AI coding assistants like GitHub Copilot,Â and offers insights on effectively leveraging these tools in aÂ Retrieval Augmented Generation framework.Â The author also discusses the potential risks and pitfalls,Â such as amplifyingÂ bad coding practices and review fatigue,Â and provides strategies for mitigating them.

### **Multi-Agent-as-a-Service â€” A Senior Engineer's Overview**

Read time: 9 minutes



This article explores how senior engineers can leverage cloud-native principles to build scalable,Â secure,Â and highlyÂ available multi-agent systems.Â It introduces the concept of "Multi-Agent-as-a-Service" (MAaaS),Â which applies bestÂ practices from cloud applications to agent development and deployment.Â The author demonstrates a multi-agent debateÂ system builtÂ onÂ [this approach]("https://towardsdatascience.com/multi-agent-as-a-service-a-senior-engineers-overview-fc759f5bbcfa"),Â highlighting key components like service-oriented architecture,Â API gateways,Â and centralized monitoring to ensureÂ reliable and cost-effective AI agents in production environments.

### **Long Context RAG Performance of LLMs**

Read Time: 12 minutes



[This article]("https://www.databricks.com/blog/long-context-rag-performance-llms")Â explores the impact of increasedÂ context length on the performance of Retrieval Augmented Generation (RAG) systems,Â which leverage LLMs to enhance accuracy by retrieving relevant information.Â The authors ranÂ over 2,000 experiments on 13 popular LLMs and found that while longer context can benefit RAG,Â most models sufferÂ decreased performance after a certain context size.Â The article also analyzes unique failure patterns in long-contextÂ models,Â highlighting the need for further research to improve long-contextÂ capabilities.

### **Can Mixture of Experts (MoE) Models Push GenAI to the Next Level?**

Read time: 10 minutes



This article explores how Mixture of Experts (MoE) models,Â which use specialized submodels for different tasks,Â canÂ help address the scalability,Â computational efficiency,Â and generalization challenges faced by modern Generative AIÂ models.Â ItÂ highlightsÂ [MoE applications in language, vision, and recommendation systems]("https://pub.towardsai.net/can-mixture-of-experts-moe-models-push-genai-to-the-next-level-8951d2f85283"),Â and covers notable MoEÂ models like Mistral Mixtral 8x7B,Â Switch Transformers,Â and V-MoE.Â The author believes that as GenAI continues to evolve,Â the role of MoE models will become crucial in pushing the boundaries of what's possible withÂ AI.

##

## ðŸ§°Â **TOOLS**

### **LLM-Aided OCR: Enhancing Tesseract with Large Language Models**

Read time: 9 minutes

[The LLM-Aided OCR project]("https://github.com/Dicklesworthstone/llm_aided_ocr") is an advanced system that leverages LLMs to significantly enhance the accuracy of Optical Character Recognition (OCR) output. By combining Tesseract OCR with LLM-based error correction and formatting, the project transforms raw OCR text into high-quality, readable documents. This tool allows software developers to integrate powerful OCR capabilities into their applications, boosting productivity and access to digitized content.

### **RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation**

Read Time: 6 minutes



[RAG Foundry]("https://github.com/IntelLabs/RAGFoundry") is a framework that helps software developers improve LLM performance on retrieval-augmented generation (RAG) tasks. It provides tools for creating RAG-augmented datasets, training LLMs using parameter-efficient fine-tuning, and evaluating the models using RAG-specific metrics. The modular, configurable design enables easy experimentation with different RAG techniques, making it a valuable resource for developers looking to leverage LLMs in their applications.

### **OpenResearcher: Unleashing AI for Accelerated Scientific Research**

Read time: 8 minutes



[OpenResearcher]("https://github.com/GAIR-NLP/OpenResearcher") is an advanced Scientific Research Assistant that leverages the arXiv corpus to provide the latest scientific insights. This open-source tool supports various large language models, including those from OpenAI, Deepseek, and Hugging Face, enabling software developers to explore the frontiers of science and access cutting-edge research. The platform's strong performance in areas like correctness, richness, and relevance makes it a valuable resource for developers looking to incorporate Generative AI into their applications.

### **Introducing sqlite-vec v0.1.0: a vector search SQLite extension that runs everywhere**

Read time: 8 minutes

[sqlite-vec]("https://alexgarcia.xyz/blog/2024/sqlite-vec-stable-release/index.html") is a new, lightweight vector search extension for SQLite that runs on a variety of platforms, including the browser, mobile devices, and servers. The initial "stable" v0.1.0 release focuses on fast brute-force vector search, with support for quantization and Matryoshka embeddings to optimize storage and query performance. This article covers the key features, benchmarks, and roadmap for future versions, making sqlite-vec an attractive option for software developers looking to incorporate vector search into their applications.

### **postgres.new: In-browser Postgres with an AI Interface**

Read time: 9 minutes

[postgres.new]("https://supabase.com/blog/postgres-new") is an in-browser Postgres sandbox that pairs a WASM version of Postgres with a large language model. This enables AI-driven database development, allowing software developers to quickly import CSV data, generate reports and charts, and even build database diagramsâ€”all within a disposable, browser-based environment. The article covers the technical details behind this innovative tool, highlighting its potential to revolutionize how developers interact with and leverage Postgres in their applications.

### **Transformer Explainer: LLM Transformer Model Visually Explained**

Read time: 10 minutes



[This interactive article]("https://poloclub.github.io/transformer-explainer/") provides a detailed, visual explanation of the Transformer architecture that powers large language models like GPT. It covers the core components, including embedding, attention, and output probabilities, with step-by-step illustrations and explorable demos. This resource is invaluable for software developers seeking to understand the inner workings of these powerful AI models and leverage them in their applications.

## ðŸ“°Â **NEWS & EDITORIALS**

### **Why I bet on DSPy**

Read time: 8 minutes

[DSPy]("https://blog.isaacmiller.dev/posts/dspy")Â is an open-source framework that helps developers compose multiple LLMÂ calls together to solve real-world problems.Â The article explains how DSPy forces developers to define clear successÂ criteria and connect LLM outputs to verifiable feedback,Â rather than relying on unconstrained LLM "reasoning." ItÂ highlights DSPy's approach of using LLMs as creative engines and optimizing prompts based on measurable improvements,Â rather than treating LLMs as general reasoning systems.Â The article ultimately advocates for DSPy as a reliable tool forÂ leveraging LLMs to tackle challenging problems.

### **350M Tokens Don't Lie: Love And Hate In Hacker News**

Read Time: 10 minutes



This article providesÂ aÂ [deep dive into the sentiment and topics discussed on Hacker News]("https://outerbounds.com/blog/hacker-news-sentiment/"),Â a popular online community forÂ software developers.Â By analyzing over 350 million tokens from 100,000 posts and 230 million words of comments,Â theÂ authors used large language models to uncover the Hacker News community's love for topics like programming,Â open source,Â and nostalgia,Â as well as their disdain for subjects like FTX,Â police misconduct,Â and cost-cutting.Â The authors alsoÂ share their process,Â built on the open-source Metaflow framework,Â making this an insightful resource for developersÂ interested in leveraging Generative AI for similar data analysisÂ projects.

### **MIT Researchers Use Large Language Models to Flag Problems in Complex Systems**

Read Time: 9 minutes

Researchers at MIT have developed a frameworkÂ calledÂ [SigLLM]("https://news.mit.edu/2024/researchers-use-large-language-models-to-flag-problems-0814")Â that leveragesÂ large language models (LLMs) to detectÂ anomalies in time-series data,Â such as measurements from wind turbines or satellites.Â Unlike traditional deep learningÂ approaches,Â SigLLM can be deployed "off-the-shelf" without the need for extensive training,Â making it a more efficientÂ solution for techniciansÂ to identify potential problems in complex systems.Â While LLMs currently lag behind state-of-the-art deep learning models,Â the researchers are optimistic that furtherÂ improvements could make LLM-based anomaly detection a "game-changer" for software developers working on complexÂ monitoring and diagnostic applications.

### **Prompt Caching with Claude: Revolutionizing AI-Powered Applications**

Read time: 8 minutes



[Prompt caching with Anthropic's Claude AI]("https://www.anthropic.com/news/prompt-caching")Â enables developers toÂ dramatically reduce costs and latency when using large language models.Â By caching frequently used context,Â Claude canÂ deliver faster responses and save up to 90%Â on costs for use cases like conversational agents,Â coding assistants,Â andÂ document processing.Â This public beta feature is now available for Claude 3.5 Sonnet and Claude 3 Haiku,Â with supportÂ for Claude 3 Opus coming soon.

### **Hermes 3: A New Frontier for Open-Source AI**

Read time: 6 minutes

[Hermes 3]("https://nousresearch.com/hermes3/")Â is a powerful open-source AI model developed by Nous Research.Â It boastsÂ advanced capabilities like long-term context retention,Â multi-turn conversation,Â complex roleplaying,Â and enhancedÂ agentic function-calling.Â Hermes 3 was created by fine-tuning the LLaMA 3.1 model,Â offering comparable and superiorÂ performance to the base model.Â This novel AI system encourages developers to experiment with individual-alignment,Â artificial consciousness,Â and decentralized technology in ways that traditional companies may be hesitant to explore.

**Thanks for reading, and we will see you next time**

Follow me on [LinkedIn]("http://Follow me on LinkedIn: www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=samkeen") or [Threads](https://www.threads.net/@sam.keen"https://www.threads.net/@sam.keen")
