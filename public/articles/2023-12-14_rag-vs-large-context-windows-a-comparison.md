---
title: ðŸ†š RAG vs Large Context Windows; a Comparison
author: Sam Keen
date: December 14, 2023
url: https://devthink.ai/p/rag-vs-large-context-windows-a-comparison
scraped_at: 2025-07-29T19:27:10.937587
---

# ðŸ†š RAG vs Large Context Windows; a Comparison

*By Sam Keen on December 14, 2023*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

In this edition: Itâ€™s been interesting to see the evolution of standard architectures around GenAI applications. We are covering a lot of the usual suspects, RAG and Agent workflows but with examples that show the progression these mechanisms have made. Iâ€™m also looking forward to trying out Jetbrainâ€™s coding copilot.

- ðŸ“– TUTORIALS & CASE STUDIES
- ðŸ§° TOOLS
- ðŸ“° NEWS

## ðŸ“–Â **TUTORIALS & CASE STUDIES**

**Workshop on Fine-Tuning LLM Agents for Task Automation**  
read time: 1hr presentation  
Join this [online workshop]("https://www.eventbrite.com/e/llm-agent-fine-tuning-enhancing-task-automation-with-weights-biases-tickets-771861728207") from DeepLearning.AI to learn how to enhance the performance of Large Language Model (LLM) agents in application automation. Topics include fine-tuning techniques, metrics and logging, debugging with Weights & Biases, prompting paradigms, and practical evaluation with W&B.

**Improving Contextual Recall with Claude 2.1**  
read time: 8 minutes  
Anthropic's AI model, [Claude 2.1]("https://www.anthropic.com/index/claude-2-1-prompting"), offers a 200K token context window, excelling at real-world retrieval tasks. However, it can be hesitant to answer questions based on out-of-place sentences. A minor prompting edit can overcome this reluctance, improving performance on these tasks.

**RAG vs. Context-Window in GPT-4: A Comparative Analysis**  
read time: 15 minutes  
This [article]("https://ai88.substack.com/p/rag-vs-context-window-in-gpt4-accuracy-cost") presents a detailed comparison between Retrieval Augmented Generation (RAG) and context-window stuffing in GPT-4. The study reveals that RAG, when combined with GPT-4, delivers superior performance at just 4% of the cost, making it a more efficient choice for specializing Large Language Models' responses.

**Evaluating Retrieval-Augmented Generation Applications with RAGAs**  
read time: 15 minutes



This [article]("https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a") introduces RAGAs, a framework for evaluating Retrieval-Augmented Generation (RAG) applications. It provides metrics for assessing the performance of RAG pipelines and leverages Large Language Models for reference-free evaluation, making it a cost-effective solution.

##

## ðŸ§°Â **TOOLS**

**Mistral AI Launches Beta Access to Generative AI Platform**  
read time: 5 minutes  
Mistral AI has launched beta access to its platform, offering developers powerful generative models and efficient deployment methods. The platform includes three chat endpoints for text generation and an embedding endpoint. The models are pre-trained on open web data and fine-tuned for instructions. Learn more about the platform and its capabilities in the [full article]("https://mistral.ai/news/la-plateforme/").

**KwaiAgents: Open-Sourced Agent-Related Works by Kuaishou Technology**  
read time: 15 minutes



Kuaishou Technology has open-sourced a series of agent-related works, [KwaiAgents]("https://github.com/kwaikeg/kwaiagents"), including KAgentSys-Lite, KAgentLMs, KAgentInstruct, and KAgentBench. These tools offer capabilities such as planning, reflection, and tool-use, and provide a benchmark for testing agent capabilities. The guide also includes instructions for deploying and using these tools.

**Microsoft's Phi-2: The Surprising Power of Small Language Models**  
read time: 10 minutes

Microsoft Research's Machine Learning Foundations team has released [Phi-2]("https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/"), a 2.7 billion-parameter language model that outperforms models up to 25x larger on complex benchmarks. The model's performance is attributed to strategic training data selection and innovative scaling techniques.

**Anyscale Endpoints Introduces JSON Mode and Function Calling**  
read time: 15  
Anyscale Endpoints has introduced JSON mode and function calling capabilities, enhancing the usability of open models like Mistral-7B. JSON mode ensures valid JSON outputs tailored to specific schema requirements. Function calling allows models to use APIs effectively. These features are currently in preview for the Mistral-7B model. Read more about these exciting updates [here]("https://www.anyscale.com/blog/anyscale-endpoints-json-mode-and-function-calling-features").

**Ollama: A Local Solution for Large Language Models**  
read time: 8 minutes  
Ollama is a tool that allows developers to run large language models locally. It supports a variety of open-source models and provides a simple API for creating, running, and managing models. It also offers customization options and a REST API for running and managing models. Learn more about it [here]("https://github.com/jmorganca/ollama").

## ðŸ“°Â **NEWS**

**Leveraging AI for Secure Code Development**  
read time: 8 minutes  
This [article]("https://www.linkedin.com/pulse/how-developers-can-use-ai-secure-code-github-irwdc/") discusses how AI and automation can enhance DevSecOps by providing personalized training, identifying vulnerabilities, managing dependencies, and integrating security tooling into the SDLC. It also provides tips on evaluating AI tools for adoption at work, emphasizing understanding data use, inspecting IP clauses, tracking tool performance, and auditing the tool's audits.

**JetBrains Unveils Vendor-Neutral AI Coding Assistant**  
read time: 8 minutes



JetBrains has introduced a new AI coding assistant that leverages multiple large language models (LLMs) to provide coding suggestions, refactoring, and documentation support. The assistant is vendor-neutral, using both OpenAI and Google's LLMs, along with JetBrains' own models. The AI service architecture allows for easy integration of new models. Currently, the offering is only available to paying customers. Read more about it [here]("https://thenewstack.io/jetbrains-launches-new-ai-assistant-powered-by-multiple-llms/").

**Google's Duet AI: Revolutionizing the Software Development Lifecycle**  
read time: 15 minutes  
Google has launched [Duet AI for Developers]("https://thenewstack.io/googles-duet-ai-launches-genai-across-full-sdlc-in-the-cloud/"), a generative AI tool designed to assist developers throughout the entire software development lifecycle. The tool integrates with IDEs and Google's Cloud Console, offering coding assistance, chat support, and ops tooling. Duet AI aims to increase developer productivity by reducing cognitive load and streamlining workflows.

**Thanks for reading and we will see you next time**

Follow me on [twitter]("https://twitter.com/devthinkai"), DM me links you would like included in a future newsletters.
