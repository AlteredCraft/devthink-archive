---
title: Building Agentic RAG with LlamaIndex
author: Sam Keen
date: May 13, 2024
url: https://devthink.ai/p/building-agentic-rag-with-llamaindex
scraped_at: 2025-07-29T19:24:13.340761
---

# Building Agentic RAG with LlamaIndex

*By Sam Keen on May 13, 2024*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

Thank you for being a loyal subscriber to our newsletter! This week, we have an incredible lineup of content that I'm sure you'll find immensely valuable. Dive into our tutorials on building intelligent Retrieval Augmented Generation (RAG) systems, learn how to easily run large language models (LLMs) locally, and explore the latest developments in AI-powered coding tools like GitHub Copilot Workspace. Don't miss our insights on the evolving world of generative AI â€“ this is a must-read issue you won't want to miss!



## ðŸ“–Â **TUTORIALS & CASE STUDIES**

### **Building Agentic RAG with LlamaIndex**

Read time: 9 minutes

This [short course]("https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex") teaches software developers how to build an intelligent "agentic" Retrieval Augmented Generation (RAG) system using the LlamaIndex framework.Â Developers will learn to create a versatileÂ research agent that can reason over documents,Â answer complex questions,Â and handle multi-document scenarios.Â The courseÂ covers building a router agent,Â adding tool-calling capabilities,Â and developing a fully autonomous research assistantÂ agentÂ -Â equipping developers with powerful AI-powered data analysis and decision-making capabilities.

### **Ollama Tutorial: Running LLMs Locally Made Super Simple**



Read time: 8 minutes

[This article]("https://www.kdnuggets.com/ollama-tutorial-running-llms-locally-made-super-simple")Â introduces Ollama,Â aÂ platform that simplifies local development with open-source large language models (LLMs).Â It provides a step-by-stepÂ guide on downloading Ollama,Â obtaining LLM models,Â and running them locally,Â including customizing model behavior withÂ system prompts and integrating Ollama with Python using the official library or LangChain.Â This tutorial empowersÂ software developers to easily experiment with and leverage LLMs in their applications,Â staying competitive in theÂ evolving AI landscape.

### **Routing in RAG-Driven Applications**



Read Time: 8 minutes

This article explores the importance of routing in Retrieval Augmented Generation (RAG) applications,Â where the flow ofÂ a user's query is directed to the appropriate data sources and processing components.Â It discusses various types ofÂ natural language routers,Â such as LLM Completion Routers,Â LLM Function Calling Routers,Â Semantic Routers,Â and Zero ShotÂ Classification Routers,Â which can help create more powerful and useful RAG applications.Â The author also comparesÂ routers to agents,Â highlighting their similarities and differences.Â By understanding these routing concepts,Â softwareÂ developers canÂ leverageÂ [generative AI tools]("https://towardsdatascience.com/routing-in-rag-driven-applications-a685460a7220")Â to buildÂ more robust and flexible applications.

### **How LLMs Work, Explained Without Math**

Read Time: 12 minutes

[This article]("https://blog.miguelgrinberg.com/post/how-llms-work-explained-without-math") provides a high-level,Â non-technical explanation of how Large Language Models (LLMs) work,Â focusing on theÂ core concepts of tokens,Â next token prediction,Â and text generation.Â It discusses the training process,Â the limitationsÂ of simple Markov chain approaches,Â and the evolution to neural networks and transformer architectures.Â While the authorÂ notes LLMs do not yet display true intelligence,Â they demonstrate the sophisticated ability to generate text byÂ stitching together patterns learned from training data.Â This overview equips software developers with a foundationalÂ understanding of the mechanics behind these increasinglyÂ important generative AI tools.

### **RAG Development with Pinecone Serverless**

Read Time: 13 minutes

This article provides a step-by-step guide for software developers on building Retrieval Augmented Generation (RAG) applications using Pinecone's serverless vector database,Â OpenAI,Â and LangChain.Â It covers key steps like reading andÂ chunking text data,Â generating embeddings,Â storing vectors and metadata in Pinecone,Â querying the database,Â andÂ leveraging a Large Language Model to generate high-quality responses.Â The author highlights Pinecone's advantages forÂ RAG development and offers code samples to help readers quickly set up and deploy their own RAGÂ applications.Â [This guide]("https://3rdson.hashnode.dev/step-by-step-guide-to-developing-rag-applications-with-pinecone-serverless-openai-langchain-and-python")Â is a valuable resource for software developers looking to incorporate generative AI capabilities into their projects.

##

## ðŸ§°Â **TOOLS**

### **A Framework to Detect Hallucinations in the Text Generated by LLMs**



Read Time: 7 minutes

Researchers have developedÂ [KnowHalu]("https://techxplore.com/news/2024-05-framework-hallucinations-text-generated-llms.html"),Â a novel framework to detect hallucinations inÂ the text generated by large language models (LLMs).Â KnowHalu employs a two-phase process to identify both fabricated andÂ non-fabricated hallucinations,Â utilizing multi-form knowledge-based fact checking to assess the accuracy and relevanceÂ of LLM outputs.Â This framework could help improve the reliability of LLMs and enable their broader real-worldÂ application in software development tasks.

### **The Next Big Programming Language Is English**



Read time: 9 minutes

[GitHub Copilot Workspace]("https://every.to/chain-of-thought/i-spent-24-hours-with-github-copilot-workspaces")Â is aÂ powerful AI-powered tool that allows software developers to code in plain English,Â automating the process of writing,Â testing,Â and implementing code.Â While still in technical preview,Â this "agent" system represents the future ofÂ programming,Â where natural language interfaces will become the norm for building applications.Â The article explores theÂ capabilities and limitations of Copilot Workspace,Â highlighting its potential to speed up common development tasks andÂ the importance of understanding its strengths and weaknesses as a "model manager" for such AI-powered programming tools.

### **LeRobot: State-of-the-art Machine Learning for Real-World Robotics in Pytorch**



Read Time: 8 minutes

[LeRobot]("https://github.com/huggingface/lerobot")Â is an open-source library that provides models,Â datasets,Â and toolsÂ for leveraging state-of-the-art machine learning techniques in real-world robotics projects.Â Aimed at softwareÂ developers,Â LeRobot offers pretrained models,Â simulation environments,Â and integration with popular frameworks likeÂ Weights and Biases,Â allowing users to quickly build and evaluate robotics applications.Â The library includes support forÂ imitation learning,Â reinforcement learning,Â and other cutting-edge approaches,Â making it a valuable resource for stayingÂ competitive in the evolving field of robotics and generative AI.

## ðŸ“°Â **NEWS & EDITORIALS**

### **5 Lessons From LinkedIn's First Foray Into GenAI Development**

Read Time: 8 minutes

This article shares key learnings from LinkedIn's experience building generative AI (GenAI) features,Â including theÂ importance of managing expectations,Â leveraging Retrieval Augmented Generation (RAG) to enhance LLM capabilities,Â andÂ the challenges of evaluating subjective GenAI outputs.Â It also emphasizes the trade-offs between latency and accuracyÂ when deploying GenAI in productionÂ applications.Â [These insights]("https://thenewstack.io/5-lessons-from-linkedins-first-foray-into-genai-development/")Â canÂ help software developers navigate the complexities of incorporating GenAI into their own tools and applications.

### **IBM Releases Open-Source Granite Code Models, Outperforming Llama 3**

Read Time: 5 minutes

IBM has released four powerful open-source Granite code models,Â ranging from 3 to 34 billion parameters,Â that outperformÂ models like Llama 3 in code generation,Â debugging,Â and other key tasks.Â These models,Â trained on 500 million lines ofÂ code across 50+Â languages,Â help developers write,Â test,Â and ship reliable software moreÂ efficiently. The [Granite code models]("https://analyticsindiamag.com/ibm-releases-open-source-granite-code-models-outperforms-llama-3/") are available on Hugging Face, GitHub, and other platforms for software developers to leverage in their applications.

### **Llama 3 vs. GPT-4: The Open-Source Showdown**

Read Time: 12 minutes

This article provides an in-depth comparison of the open-sourceÂ [Llama 3]("https://myscale.com/blog/llama-3-vs-gpt-4/")Â and the proprietary GPT-4 AI models.Â While GPT-4 outperforms Llama 3 on some metrics,Â Llama 3's open-source natureÂ enables collaboration,Â transparency,Â and broader experimentation.Â The article also highlights MyScaleDB,Â a scalableÂ vector database designed for AI applications that offers free storage to new users.

**Thanks for reading and we will see you next time**

Follow me on [twitter]("https://twitter.com/samkeen"), DM me links you would like included in a future newsletters.
