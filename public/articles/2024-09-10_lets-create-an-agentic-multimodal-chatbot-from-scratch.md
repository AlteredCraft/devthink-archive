---
title: Let's Create an Agentic Multimodal Chatbot from Scratch
author: Sam Keen
date: September 10, 2024
url: https://devthink.ai/p/lets-create-an-agentic-multimodal-chatbot-from-scratch
scraped_at: 2025-07-29T19:21:45.895848
---

# Let's Create an Agentic Multimodal Chatbot from Scratch

*By Sam Keen on September 10, 2024*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

Welcome back, fellow developers! This week's edition is packed with insights that will empower you to harness the full potential of generative AI. From building LLMs from scratch to implementing secure Retrieval Augmented Generation (RAG) systems, we've got you covered. And don't miss the latest on cutting-edge tools like the open-source Reflection Llama-3.1 and the impressive Yi-Coder AI coding assistant. Dive in and elevate your development game!



## ðŸ“–Â **TUTORIALS & CASE STUDIES**

### Building LLMs from the Ground Up: A 3-hour Coding Workshop

Read Time: 40 minutes

[This 3-hour coding workshop]("https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up")Â providesÂ software developers a hands-on introduction to building LLMs from scratch.Â The workshop covers key topics likeÂ understanding LLM input data,Â coding an LLM architecture,Â pretraining,Â loading pretrained weights,Â and fine-tuning forÂ instruction-following.Â Attendees will gain practical experience implementing core LLM components,Â equipping them toÂ leverage these powerful AI tools in their own applications.

### **Llama3, LangGraph and Elasticsearch: Build a Local Agent for Vector Search**

Read Time: 9 minutes



[This article]("https://www.elastic.co/search-labs/blog/local-rag-agent-elasticsearch-langgraph-llama3")Â demonstrates howÂ to build a reliable agent using LangGraph,Â LLaMA3,Â and Elasticsearch Vector Store.Â The agent combines ideas fromÂ advanced Retrieval-Augmented Generation (RAG) papers,Â including adaptive routing,Â fallback retrieval,Â andÂ self-correction.Â The system is designed to be modular and scalable,Â with a predefined control flow that simplifiesÂ decision-making for the LLM.Â This enables the agent to provide high-quality,Â relevant answers to user queries byÂ leveraging local resources and tools.

### **Unleash the Power of Generative AI in Customer Support with Amazon Bedrock**

Read Time: 8 minutes



[This Anthropic QuickStart guide]("https://github.com/anthropics/anthropic-quickstarts/tree/main/customer-support-agent")Â introduces a highly customizable customer support chat interface powered by Anthropic's Claude model and Amazon Bedrock' s knowledge retrieval.Â Key features include real-time thinking displays,Â user mood detection,Â and shadcn/ui-based UIÂ customization.Â The guide covers setup,Â configuration,Â knowledge base creation,Â and deployment on AWS Amplify,Â making itÂ a valuable resource for software developers looking to leverage generative AI in their customer support applications.

### **Secure RAG Applications using Prompt Engineering on Amazon Bedrock**

Read Time: 9 minutes

[This article]("https://aws.amazon.com/blogs/machine-learning/secure-rag-applications-using-prompt-engineering-on-amazon-bedrock/")Â introduces prompt engineering security guardrails to mitigate prompt-level threats in Retrieval Augmented Generation ( RAG) applications powered by large language models on Amazon Bedrock.Â It discusses common prompt threats like injection,Â leaking,Â and jailbreaking,Â and provides a comprehensive set of prompt template guidelines to secure RAG solutions,Â including the use of salted tags and threat detection instructions.

### **How to Implement Graph RAG Using Knowledge Graphs and Vector Databases**

Read time: 10 minutes



This article provides a step-by-step tutorialÂ onÂ [leveraging knowledge graphs and vector databases]("https://towardsdatascience.com/how-to-implement-graph-rag-using-knowledge-graphs-and-vector-databases-60bb69a22759")Â to implementÂ Retrieval-Augmented Generation (RAG),Â a powerful technique for improving the accuracy and context of language modelÂ responses.Â The author demonstrates how to vectorize data into a vector database for semantic search and similarity,Â thenÂ use a knowledge graph to filter and refine the results,Â reducing the risk of "context poisoning." The article highlightsÂ the strengths and tradeoffs of each approach,Â showing how combining them can maximize the benefits ofÂ both.

### **Let's Create an Agentic Multimodal Chatbot from Scratch**

Read time: 13 minutes



This article guides software developers through the creation ofÂ anÂ ["agentic multimodal chatbot"]("https://pub.towardsai.net/lets-create-an-agentic-multimodal-chatbot-from-scratch-7087e3ae8ace")â€”a powerful AI system that can understand, generate, and respond to text, images, and audio. The author walks through integrating a large language model (Gemma), a retrieval-augmented generation (RAG) system, and image/audio generation capabilities to build a highly capable conversational AI assistant. The article covers techniques like model quantization, prompt engineering, and multimodal data processing, providing a practical example of how developers can leverage the latest advancements in generative AI.

##

## ðŸ§°Â **TOOLS**

### **Reflection Llama-3.1 70B: The World's Top Open-Source LLM**

Read time: 8 minutes

[Reflection Llama-3.1 70B]("https://huggingface.co/mattshumer/Reflection-Llama-3.1-70B")Â is the latest version of anÂ open-source LLMÂ trained using a novel "Reflection-Tuning" technique.Â This model can detect andÂ correct its own reasoning errors,Â making it a powerful tool for software developers looking to leverage advancedÂ generative AI capabilities.Â The article provides benchmarks,Â system prompts,Â and tips for optimizing the model'sÂ performance.

### **Meet Yi-Coder: A Small but Mighty LLM for Code**

Read Time: 10 minutes



[Yi-Coder]("https://01-ai.github.io/blog.html?post=en%2F2024-09-05-A-Small-but-Mighty-LLM-for-Code.md&utm_source=devthink.ai&utm_medium=referral&utm_campaign=let-s-create-an-agentic-multimodal-chatbot-from-scratch"),Â a series ofÂ open-source code LLMs,Â delivers state-of-the-art coding performance with under 10 billion parameters.Â Despite its smallÂ size,Â Yi-Coder excels at tasks like competitive programming,Â code editing,Â and mathematical reasoning,Â outperformingÂ larger models.Â The article highlights Yi-Coder's impressive benchmarking results and long-context modeling capabilities,Â making it a compelling option for software developers seeking powerful AI-powered coding assistance.

### **Chat with Your Codebase in 2 Commands**

Read Time: 6 minutes



[repo2vec]("https://github.com/Storia-AI/repo2vec")Â is an open-source tool that lets software developers chat with theirÂ codebase using a conversational AI interface.Â It indexes your code and GitHub issues,Â then allows you to query theÂ codebase and get detailed,Â contextual responses.Â With options to run locally or use cloud-based embeddings and languageÂ models,Â repo2vec provides a powerful and customizable way for developers to quickly understand and integrate newÂ codebases.

### **Lance v0.16.1 Feature Roundup**

Read Time: 9 minutes

[This article]("https://blog.lancedb.com/lance-v0-16-1-feature-roundup/")Â highlights the key new features in LanceÂ v0.16.1,Â an open-source data management framework.Â Notable updates include version tagging for dataset versioning,Â optimized subcolumn updates,Â a new file format versioning API,Â and distributed APIs for scaling up ANN index creation.Â These improvements streamline data management,Â boost performance,Â and enable more efficient processing of largeÂ datasetsÂ -Â valuable capabilities for software developers building applications with generative AI.

### **LLM Compressor: Faster Inference with vLLM**

Read Time: 8 minutes



[Neural Magic's LLM Compressor]("https://neuralmagic.com/blog/llm-compressor-is-here-faster-inference-with-vllm/")Â is aÂ unified library for creating compressed language models that enable faster inference with vLLM.Â It supports advancedÂ compression techniques like weight and activation quantization,Â allowing developers to boost performance on Nvidia GPUsÂ by up to 3x without compromising model accuracy.Â LLM Compressor integrates seamlessly with the open-source vLLM runtime,Â simplifying the deployment of optimized models.

### **An Open-Source RAG UI for Chatting with Your Documents**

Read time: 8 minutes



[Kotaemon]("https://github.com/Cinnamon/kotaemon")Â is an open-source Retrieval Augmented Generation (RAG) tool thatÂ provides a clean and customizable web UI for chatting with your documents.Â It supports both end-users and developers,Â offering features like multi-modal QA,Â complex reasoning,Â and configurable settings.Â Kotaemon also allows you to hostÂ your own document QA system,Â organize LLM and embedding models,Â and extend the UI to fit your specific needs.Â ThisÂ project aims to make it easier for software developers to leverage generative AI in their applications.

## ðŸ“°Â **NEWS & EDITORIALS**

### **AI Demands More Than Just Technical Skills From Developers**

Read Time: 8 minutes

The integration of AI into development environments is reigniting the debate around theÂ [skills developers need to succeed]("https://thenewstack.io/ai-demands-more-than-just-technical-skills-from-developers/").Â Employers now value "well-rounded" developers who can think critically,Â adapt,Â solve problems,Â and leverage AIÂ assistants effectively.Â Key soft skills include reasoning,Â curiosity,Â creativity,Â and accountability.Â Developers mustÂ fully understand the problem and desired outcome before using GenAI tools,Â and treat them as collaborative partners,Â notÂ just blindly following prompts.

### **Debate over "Open Source AI" Term Brings Push for Clear Definition**

Read Time: 9 minutes

The Open Source Initiative (OSI) is working to establishÂ aÂ [clear definition of "open source AI"]("https://arstechnica.com/information-technology/2024/08/debate-over-open-source-ai-term-brings-new-push-to-formalize-definition/")Â as some companiesÂ release AI models with usage restrictions while labeling them as "open source." The proposed definition emphasizes "fourÂ fundamental freedoms" for users,Â including the ability to use,Â study,Â modify,Â and share the AI system.Â By providing aÂ benchmark for open source AI,Â the OSI aims to promote transparency,Â collaboration,Â and "permissionless innovation" inÂ this fast-movingÂ field.

### **AI Has Created a Battle Over Web Crawling**

Read time: 10 minutes

[This article]("https://spectrum.ieee.org/web-crawling")Â explores how the rise of generative AI has led many websites toÂ restrict web crawlers through robots.txt,Â limiting the data available to train these models.Â The report finds that 25%Â of data from top websites has been revoked,Â shifting the training data towards lower-quality sources.Â The articleÂ discusses the implications for AI companies,Â synthetic data as a potential solution,Â and the need for new standards toÂ allow creators to express their data preferences.

### **100M Token Context Windows**

Read time: 8 minutes

[This article]("https://magic.dev/blog/100m-token-context-windows")Â discusses Magic's progress on ultra-long contextÂ models that can reason on up to 100 million tokens of context during inference.Â These models could revolutionize codeÂ synthesis by providing developers access to an entire codebase,Â including private libraries,Â during code generation.Â TheÂ article also announces Magic's partnership with Google Cloud to build a powerful AI supercomputer and their recent $465MÂ in funding to accelerate this research.

**Thanks for reading, and we will see you next time**

Follow me on [LinkedIn]("http://Follow me on LinkedIn: www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=samkeen") or [Threads](https://www.threads.net/@sam.keen"https://www.threads.net/@sam.keen")
