---
title: Corrective RAG (CRAG): Improving RAG with Enhanced Document Retrieval
author: Sam Keen
date: September 24, 2024
url: https://devthink.ai/p/introducing-contextual-retrieval-boosting-performance-of-rag-systems
scraped_at: 2025-07-29T19:21:28.967790
---

# Corrective RAG (CRAG): Improving RAG with Enhanced Document Retrieval

*By Sam Keen on September 24, 2024*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

Thank you for being a loyal subscriber to our newsletter! This week, we have an exceptional lineup of content that I'm confident you'll find valuable. Dive into the latest advancements in Retrieval Augmented Generation, discover new AI tools like AutoGluon and WordLlama, and get insights on the evolving landscape of large language models. From thought-provoking editorials to practical tutorials, this issue is packed with information to help you stay ahead in the world of generative AI.

## ðŸ“–Â **TUTORIALS & CASE STUDIES**

### **Contextual Retrieval: Boosting Performance of RAG for Large Knowledge Bases**

Read time: 9 minutes



[Anthropic's Contextual Retrieval]("https://www.anthropic.com/news/contextual-retrieval")Â is a novel technique thatÂ significantly improves the retrieval accuracy of RAG systems by preserving context when embedding and indexing knowledgeÂ base chunks.Â By combining Contextual Embeddings and Contextual BM25,Â Contextual Retrieval can reduce retrieval failureÂ rates by up to 49%.Â When further combined with reranking,Â the failure rate drops by 67%,Â unlocking new levels ofÂ performance for large-scale knowledge base applications.

### **A Visual Exploration of Semantic Text Chunking**

Read Time: 10 minutes

ThisÂ [article]("https://towardsdatascience.com/a-visual-exploration-of-semantic-text-chunking-6bb46f728e30")Â demonstratesÂ how software developers can leverage semantic chunking and visualization techniques to enhanceÂ Retrieval Augmented Generation (RAG) and other applications that leverage LLMs.Â It exploresÂ methods to split text into coherent chunks,Â visualize the chunking process,Â and use clustering and LLM-powered labelingÂ to gain insights from the generated chunks.Â The author provides a step-by-step walkthrough and Python code to applyÂ these techniques on example texts,Â including the Wizard of Oz,Â illustrating how the approach can be adapted to differentÂ corpora.

### **Corrective RAG (CRAG): Improving RAG with Enhanced Document Retrieval**

Read Time: 8 minutes



[Corrective RAG (CRAG)]("https://www.datacamp.com/tutorial/corrective-rag-crag")Â is an enhanced version of theÂ Retrieval-Augmented Generation (RAG) framework that improves language model accuracy by actively checking and refiningÂ retrieved documents before using them for text generation.Â CRAG incorporates a retrieval evaluator,Â web searchÂ capabilities,Â and a query refinement process to reduce the risk of generating misleading content,Â making it a valuableÂ tool for software developers leveraging generative AI in their applications.

### **Benchmarking Hallucination Detection Methods in RAG**

Read time: 8 minutes



This article evaluates various techniques for automatically detecting hallucinationsÂ -Â incorrect LLM responsesÂ -Â inÂ Retrieval Augmented Generation (RAG) systems.Â By comparing methods like Trustworthy Language Model,Â Self-Evaluation,Â andÂ RAGAS Faithfulness across multiple RAG datasets,Â the author identifies the most reliable approaches for ensuring theÂ accuracy and trustworthiness of RAG-generated answers,Â which is crucial for high-stakes applications.Â TheÂ [detailed benchmarks and insights]("https://towardsdatascience.com/benchmarking-hallucination-detection-methods-in-rag-6a03c555f063")Â provide software developers valuable guidance on enhancing the reliability of their RAG-based applications.

### **Choosing Between LLM Agent Frameworks**

Read time: 9 minutes



This article explores the tradeoffsÂ betweenÂ [building custom code-based agents and using the major agent frameworks]("https://towardsdatascience.com/choosing-between-llm-agent-frameworks-69019493b259"),Â LangGraph and LlamaIndex Workflows.Â It provides a technical comparison of implementing the same agent across theseÂ approaches,Â highlighting the strengths and challenges of each.Â The author concludes that the choice ultimately dependsÂ on factors like existing investments in LlamaIndex or LangChain,Â familiarity with agent structures,Â and availability ofÂ framework-specific examples.Â Importantly,Â the article emphasizes the need for robust guardrails and LLM tracing whenÂ deploying generative AI systems inÂ production.

##

## ðŸ§°Â **TOOLS**

### **Fast and Accurate ML in 3 Lines of Code**

Read time: 5 minutes



[AutoGluon]("https://github.com/autogluon/autogluon")Â is an open-source library that enables software developers toÂ quickly and easily integrate state-of-the-art machine learning models into their applications.Â With just 3 lines ofÂ code,Â developers can train highly accurate models across a variety of supervised learning tasks,Â including tabular,Â image,Â and text data.Â The framework's automated model selection and tuning capabilities make it a powerful tool forÂ developers looking to leverage advanced AI capabilities in their software projects.

### **Recycled Token Embeddings for Efficient NLP: WordLlama**

Read time: 5 minutes



[WordLlama]("https://github.com/dleemiller/WordLlama")Â is a lightweight NLP toolkit that leverages token embeddings fromÂ large language models (LLMs) to enable efficient CPU-based NLP tasks.Â It offers features like fuzzy deduplication,Â similarity ranking,Â and clustering,Â while being much smaller in size than traditional word embedding models.Â WordLlama'sÂ Matryoshka representation learning approach allows developers to tradeoff model size and performance,Â making it aÂ versatile choice for building AI-powered applications that require fast,Â portable NLP capabilities.

### **AI for JQ: A Powerful CLI for Generative AI Workflows**

Read time: 8 minutes

[aiq]("https://github.com/taylorai/aiq")Â is a CLI tool that enables software developers to seamlessly integrate generativeÂ AI into their workflows.Â It provides commands to label text using LLMs,Â compute text embeddings,Â train text classifiers,Â and perform inferenceÂ -Â all while operating on text and JSON data streams.Â The tool's modular and composable designÂ allows developers to chain these commands together,Â creating powerful pipelines to leverage generative AI in theirÂ applications.

## ðŸ“°Â **NEWS & EDITORIALS**

### **Announcing Pixtral 12B: A Powerful Multimodal AI Model for Software Developers**

Read time: 7 minutes

[Pixtral 12B]("https://mistral.ai/news/pixtral-12b/")Â is a new multimodal AI model from Mistral that can understand bothÂ images and text,Â excelling in tasks like chart analysis,Â document question answering,Â and multimodal instructionÂ following.Â Pixtral maintains state-of-the-art performance on text-only benchmarks while delivering best-in-classÂ multimodal reasoning,Â making it a valuable tool for software developers leveraging generative AI in their applications.

### **Notes on OpenAI's New o1 Chain-of-Thought Models**

Read time: 8 minutes

[This article]("https://simonwillison.net/2024/Sep/12/openai-o1/")Â explores OpenAI's new o1-preview and o1-mini models,Â which are designed to "spend more time thinking" through complex prompts using a reinforcement learning-basedÂ chain-of-thought approach.Â The models offer improved reasoning capabilities but come with trade-offs in cost,Â performance,Â and transparency.Â The article discusses key details,Â examples,Â and implications for software developersÂ leveraging generative AI in their applications.

### **Forget ChatGPT: Why Researchers Now Run Small AIs on Their Laptops**

Read time: 9 minutes

[This article]("https://www.nature.com/articles/d41586-024-02998-y")Â explores how software developers are increasinglyÂ turning to small,Â open-source Large Language Models (LLMs) that can run on their local devices.Â These models,Â such asÂ Phi-3 from Microsoft,Â rival the performance of larger cloud-based models like ChatGPT,Â while offering benefits like costÂ savings,Â privacy preservation,Â and reproducibility.Â The article highlights use cases in bioinformatics,Â healthcare,Â andÂ industry,Â showcasing how researchers are leveraging these accessible AI tools to enhance their work.

### **Jumping Over AI's Uncanny Valley**

Read time: 12 minutes



This article explores the Uncanny Valley,Â a psychological phenomenon that could eitherÂ [hinder or help the adoption of advanced AI technologies]("https://every.to/p/jumping-over-ai-s-uncanny-valley-4b1c3436-b424-4a62-b563-50e1469bba6c")Â likeÂ humanoid robots and AI-generated content.Â While the existence of the Uncanny Valley isÂ debated,Â the author argues it is worth investigating,Â as it could impact how developers leverage AI as a tool versus aÂ replacement for human abilities.Â The piece provides insights on navigating the Uncanny Valley and suggests opportunitiesÂ for companies that embrace AI's limitations rather than maskÂ them.

### **Scaling: The State of Play in AI**

Read Time: 11 minutes



This article provides an overview of the current state of Large Language Models (LLMs),Â focusing on the importance ofÂ scale and the progression of model generations from ChatGPT-3.5 to the upcoming GPT-5 and Grok 3.Â It compares theÂ capabilities of five leading Gen2 frontier models,Â including GPT-4o,Â Claude 3.5 Sonnet,Â and Gemini 1.5 Pro,Â andÂ highlights the emergence of a new "thinking" scaling law that could drive furtherÂ advancements.Â [This in-depth analysis]("https://www.oneusefulthing.org/p/scaling-the-state-of-play-in-ai")Â will helpÂ software developers stay informed on the latest trends in generative AI tools and their implications.

**Thanks for reading, and we will see you next time**

Follow me on [LinkedIn]("http://Follow me on LinkedIn: www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=samkeen") or [Threads](https://www.threads.net/@sam.keen"https://www.threads.net/@sam.keen")
