---
title: Master LangChain and Generative AI with Six Practical Projects
author: Sam Keen
date: February 04, 2024
url: https://devthink.ai/p/master-lang-chain-and-generative-ai-with-six-practical-projects
scraped_at: 2025-07-29T19:26:22.268381
---

# Master LangChain and Generative AI with Six Practical Projects

*By Sam Keen on February 04, 2024*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**



## ðŸ“–Â **TUTORIALS & CASE STUDIES**

### Open-Source LLMs: Powering Agent Workflows



read time: 30 minutes  
Open-source Large Language Models (LLMs) are now capable of powering agent workflows, with Mixtral even surpassing GPT-3.5 in performance. This [article]("https://huggingface.co/blog/open-source-llms-as-agents") explains how to build LLM agents using the ChatHuggingFace class in LangChain and benchmarks several open-source LLMs against GPT-3.5 and GPT-4.

### Enhancing AI with Retrieval Augmented Generation (RAG)



read time: 30 minutes  
This [article]("https://python.langchain.com/docs/use_cases/question_answering/") provides an in-depth look at Retrieval Augmented Generation (RAG), a technique used to enhance Large Language Models (LLMs) with additional data. It discusses the architecture of RAG applications, including indexing and retrieval, and offers guidance on building Q&A applications using RAG.

### Choosing the Right Technique: Prompt Engineering vs Fine-Tuning

read time: 10 minutes  
This [article]("https://www.datasciencecentral.com/choosing-the-right-technique-prompt-engineering-vs-fine-tuning/") explores the role of prompt engineering and fine-tuning in enhancing the performance of Generative AI models. It explains how prompt engineering optimizes user inputs to elicit better responses, while fine-tuning refines pre-trained models for specific tasks. The article also highlights the differences between the two techniques.

### Master LangChain and Generative AI with Six Practical Projects

read time: 15 minutes  
A new course on the [freeCodeCamp.org YouTube channel]("https://www.freecodecamp.org/news/learn-langchain-and-gen-ai-by-building-6-projects/") teaches how to integrate advanced language models like GPT-4 into applications using LangChain. The course includes six end-to-end projects, providing hands-on experience with LangChain, GPT-4, Google Gemini Pro, and Llama 2.

### Code LoRA from Scratch with Lightning Studio

read time: 10 minutes  
Explore how to code LoRA from scratch with [Lightning Studio]("https://lightning.ai/lightning-ai/studios/code-lora-from-scratch"). This tutorial provides a hands-on approach to understanding and implementing LoRA, a powerful tool for generative AI applications.

##

## ðŸ§°Â **TOOLS**

### OpenAI's New and Improved Embedding Model



read time: 12 minutes  
OpenAI has launched a new model, [text-embedding-ada-002]("https://openai.com/blog/new-and-improved-embedding-model"), which outperforms previous models in text search, text similarity, and code search tasks. It replaces five separate models, offers longer context, smaller embedding size, and is priced 99.8% lower than the previous Davinci models.

### Pezzo: An Open-Source LLMOps Platform for Developers

read time: 10 minutes  
Pezzo is an [open-source, developer-first LLMOps platform]("https://github.com/pezzolabs/pezzo") designed to streamline prompt design, version management, instant delivery, collaboration, troubleshooting, observability and more. It's a valuable tool for developers looking to leverage generative AI in their applications.

### RAGxplorer: Open-Source Tool for Visualizing RAG



read time: 10 minutes  
Introducing [RAGxplorer]("https://github.com/gabrielchua/RAGxplorer"), an open-source tool designed to visualize your Retriever-Augmented Generators (RAG). This tool can be a valuable asset for developers working with generative AI models, providing a clear visual representation of RAGs.

### DeepEval: A Comprehensive Evaluation Framework for LLMs

read time: 10 minutes  
The [DeepEval]("https://github.com/confident-ai/deepeval") is a comprehensive evaluation framework for Large Language Models (LLMs). It provides a set of tools and functions to assess the performance of LLMs, making it an essential resource for developers working with generative AI and AI coding assistants.

## ðŸ“°Â **NEWS & EDITORIALS**

### Meta's Code Llama 70B: A New Milestone in Generative AI for Coding

read time: 10 minutes  
Meta's latest update, [Code Llama 70B]("https://www.theverge.com/2024/1/29/24055011/meta-llama2-code-generator-generative-ai"), outperforms previous models in code generation, scoring 53% on the HumanEval benchmark. It's built on Llama 2 and can handle more queries, aiding developers in creating and debugging code. It's free for research and commercial use.

### How Enterprises are Leveraging Open-Source Large Language Models

read time: 15 minutes  
VentureBeat explores the growing trend of enterprises deploying open-source Large Language Models (LLMs) in real business applications. Despite initial slow adoption, experts predict a significant increase in open-source LLM deployments this year. The article provides 16 examples of such deployments, including VMWare, Wells Fargo, and IBM. Read the full article [here]("https://venturebeat.com/ai/how-enterprises-are-using-open-source-llms-16-examples/").

### Hugging Face and Google Cloud: A Strategic Partnership for Open AI



read time: 5 minutes  
Hugging Face and Google Cloud have announced a [strategic partnership]("https://huggingface.co/blog/gcp-partnership") to democratize machine learning. The collaboration aims to make the latest AI research and innovations easily accessible, enabling companies to build their own AI models. The partnership will benefit Google Cloud customers and Hugging Face Hub users, offering new experiences and capabilities throughout 2024.

**Thanks for reading and we will see you next time**

Follow me on [twitter]("https://twitter.com/devthinkai"), DM me links you would like included in a future newsletters.
