---
title: Exploring Structured Reasoning in Large Language Models
author: Sam Keen
date: March 10, 2024
url: https://devthink.ai/p/exploring-structured-reasoning-in-large-language-models
scraped_at: 2025-07-29T19:25:28.420942
---

# Exploring Structured Reasoning in Large Language Models

*By Sam Keen on March 10, 2024*

---

### **Essential AI Content for Software Devs,** **Minus the Hype**

No shortage of new and tools this week, Claude 3 is impressing folks, plus a great selection of great tools and tutorials for building RAG apps.



## ðŸ“–Â **TUTORIALS & CASE STUDIES**

### Master Open Source Models with Hugging Face: A Short Course

read time: 5 minutes  
DeepLearning.AI offers a [short course]("https://www.deeplearning.ai/short-courses/open-source-models-hugging-face/") on using open source models from Hugging Face for NLP, audio, image, and multimodal tasks. The course also covers how to package your AI apps for cloud deployment using Gradio and Hugging Face Spaces.

### Implementing RAG: Writing Graph Retrieval Queries in LangChain

read time: 10 minutes



This [blog post]("https://neo4j.com/developer-blog/rag-graph-retrieval-query-langchain/") provides a detailed guide on implementing Retrieval-Augmented Generation (RAG) using LangChain for enhancing the accuracy of generative AI models. It explains how to write retrieval queries that supplement Large Language Models (LLMs) with external knowledge, using the SEC filings dataset as an example. The post also includes resources for further learning and a demo application.

### Exploring Structured Reasoning in Large Language Models

read time: 15 minutes



This [article]("https://towardsdatascience.com/something-of-thought-in-llm-prompting-an-overview-of-structured-llm-reasoning-70302752b390") provides an in-depth overview of various prompt engineering frameworks designed to enhance reasoning in Large Language Models (LLMs). It covers techniques like Chain-of-Thought, Tree-of-Thoughts, Graph-of-Thoughts, Algorithm-of-Thoughts, Skeleton-of-Thought, and Program-of-Thoughts, explaining how they improve the decision-making processes in LLMs.

### Master RAG: A Key Skill for AI Professionals in 2024

read time: 15 minutes  
LLMWare offers a free [YouTube series]("https://dev.to/llmware/become-a-rag-professional-in-2024-go-from-beginner-to-expert-41mg") to help developers understand Retrieval Augmented Generation (RAG), a fundamental aspect of working with AI models. The series covers topics from parsing and indexing to building embeddings and prompting models, aiming to equip developers with the skills needed to handle AI workflows in real-world settings.

##

## ðŸ§°Â **TOOLS**

### Introducing Claude 3: The Next Generation of AI Models

read time: 15 minutes



Anthropic introduces the [Claude 3 model family]("https://www.anthropic.com/news/claude-3-family"), setting new industry benchmarks in cognitive tasks. The family includes Claude 3 Haiku, Sonnet, and Opus, each offering increased performance. These models excel in analysis, forecasting, content creation, code generation, and multilingual conversation. They also feature improved speed, vision capabilities, accuracy, and reduced refusal rates. The models are designed to be trustworthy, bias-free, and easy to use, making them ideal for a wide range of applications.

### pg_vectorize: Simplifying Text to Embeddings Transformation in Postgres

read time: 8 minutes



pg_vectorize is a Postgres extension that simplifies the transformation of text to embeddings and the building of Large Language Model (LLM) applications. It integrates with popular LLMs and automates the creation of Postgres triggers to keep your embeddings up-to-date. Check out the [source code and API documentation]("https://github.com/tembo-io/pg_vectorize") for more details.

### Moondream2: A Compact Vision-Language Model

read time: 5 minutes  
Introducing [moondream2]("https://github.com/vikhyat/moondream2"), a 1.86B parameter model that excels in vision-language tasks. It's easy to install and use, with regular updates for improved performance. However, users should be aware of potential limitations such as societal biases and the possibility of generating inappropriate content.

### KnowAgent: Enhancing Large Language Models with Action Knowledge

read time: 8 minutes



KnowAgent is a new approach to improve the planning capabilities of Large Language Models (LLMs) by incorporating explicit action knowledge. It uses an action knowledge base and a self-learning strategy to guide planning trajectories, resulting in improved task-solving performance. Experimental results show KnowAgent's effectiveness in mitigating planning hallucinations. Learn more about it [here]("https://www.zjukg.org/project/KnowAgent/").

## ðŸ“°Â **NEWS & EDITORIALS**

### Building Large Language Models from Scratch: A Startup's Journey

read time: 15 minutes  
This [blog post]("https://www.yitay.net/blog/training-great-llms-entirely-from-ground-zero-in-the-wilderness") shares the experiences of Reka, a startup, in building large language and multimodal models from scratch. It highlights the challenges faced, including the 'hardware lottery' of compute providers, the pain of multi-cluster setups, and the quality of external codebases. Despite these hurdles, the team's strong prior knowledge and intuition helped them train competitive models with limited resources.

### Claude 3: A Leap Towards More Human-like AI

read time: 20 minutes



Anthropic's new AI model, [Claude 3]("https://every.to/napkin-math/claude-3-is-the-most-human-ai-yet"), is described as the most human-feeling, creative, and naturalistic AI yet. It outperforms its peers in certain aspects, offering a more 'warm' and nuanced interaction. Despite not outperforming the latest GPT-4 model in all benchmarks, its unique qualities could shift the vector of competition in AI development.

### Google Becomes First Customer of Stack Overflow's Paid Data Access

read time: 8 minutes  
Stack Overflow has signed Google as its first customer for paid access to its content for training AI systems. Google's cloud division will use Stack Overflow's Q&A data to enhance its Gemini chatbot's coding assistance and technical support. The deal signifies a potential new revenue stream for Stack Overflow and sets a precedent for AI developers compensating publishers for data used in AI projects. Read more about this significant development in the AI industry [here]("https://www.wired.com/story/google-deal-stackoverflow-ai-giants-pay-for-data/").

**Thanks for reading and we will see you next time**

Follow me on [twitter]("https://twitter.com/devthinkai"), DM me links you would like included in a future newsletters.
